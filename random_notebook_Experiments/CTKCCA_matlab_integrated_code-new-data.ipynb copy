{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "import matlab.engine as engi\n",
    "import matlab as mat\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.io import loadmat\n",
    "import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start matlab service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = engi.start_matlab()\n",
    "eng.addpath(r'matlab_CTKCCA/',nargout=0)\n",
    "eng.addpath(r'matlab_KS/',nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data_path = 'data/1385/converted/bzbyte.csv'\n",
    "target_data_path = 'data/1385/converted/scite-ru.csv'\n",
    "\n",
    "result_path = 'result/result.csv'\n",
    "repeats = 20\n",
    "ratio = 0.1\n",
    "lrank = 70\n",
    "reg = 1E-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,source):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop(labels = ['Host','Vcs','Project','File','PL','IssueTracking'],axis=1)\n",
    "    df = df.dropna()\n",
    "    df = df[['TLOC', 'TNF', 'TNC', 'TND', 'LOC', 'CL', 'NStmt', 'NFunc',\n",
    "    'RCC', 'MNL', 'avg_WMC', 'max_WMC', 'total_WMC', 'avg_DIT', 'max_DIT',\n",
    "    'total_DIT', 'avg_RFC', 'max_RFC', 'total_RFC', 'avg_NOC', 'max_NOC',\n",
    "    'total_NOC', 'avg_CBO', 'max_CBO', 'total_CBO', 'avg_DIT.1',\n",
    "    'max_DIT.1', 'total_DIT.1', 'avg_NIV', 'max_NIV', 'total_NIV',\n",
    "    'avg_NIM', 'max_NIM', 'total_NIM', 'avg_NOM', 'max_NOM', 'total_NOM',\n",
    "    'avg_NPBM', 'max_NPBM', 'total_NPBM', 'avg_NPM', 'max_NPM', 'total_NPM',\n",
    "    'avg_NPRM', 'max_NPRM', 'total_NPRM', 'avg_CC', 'max_CC', 'total_CC',\n",
    "    'avg_FANIN', 'max_FANIN', 'total_FANIN', 'avg_FANOUT', 'max_FANOUT',\n",
    "    'total_FANOUT', 'NRev', 'NFix', 'avg_AddedLOC', 'max_AddedLOC',\n",
    "    'total_AddedLOC', 'avg_DeletedLOC', 'max_DeletedLOC',\n",
    "    'total_DeletedLOC', 'avg_ModifiedLOC', 'max_ModifiedLOC',\n",
    "    'total_ModifiedLOC','Buggy']]\n",
    "    d = {'buggy': True, 'clean': False}\n",
    "    df['Buggy'] = df['Buggy'].map(d)\n",
    "    if source:\n",
    "        df = apply_smote(df)\n",
    "    return df\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = load_data(source_data_path,False)\n",
    "target_df = load_data(target_data_path,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matlab integration\n",
    "## Matlab integration - CTKCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(source_df,target_df):\n",
    "    mat_source_df = mat.double(source_df.values.T.tolist())\n",
    "    mat_target_df = mat.double(target_df.values.T.tolist())\n",
    "    X = eng.CTKCCA(mat_source_df,mat_target_df,nargout=4)\n",
    "    train_X,train_y = np.array(X[0]),np.array(X[1]).tolist()[0]\n",
    "    test_X,test_y = np.array(X[2]),np.array(X[3]).tolist()[0]\n",
    "    return train_X,train_y,test_X,test_y\n",
    "trasformed_train_X,trasformed_train_y,trasformed_test_X,trasformed_test_y = transform_data(source_df,target_df)\n",
    "train_df = pd.DataFrame(trasformed_train_X)\n",
    "train_df['Buggy'] = trasformed_train_y\n",
    "train_df = apply_smote(train_df)\n",
    "trasformed_train_y = train_df.Buggy\n",
    "trasformed_train_X = train_df.drop('Buggy',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.67      0.67        52\n",
      "         1.0       0.15      0.14      0.15        21\n",
      "\n",
      "    accuracy                           0.52        73\n",
      "   macro avg       0.41      0.41      0.41        73\n",
      "weighted avg       0.51      0.52      0.52        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(trasformed_train_X,trasformed_train_y)\n",
    "predicted = clf.predict(trasformed_test_X)\n",
    "print(classification_report(trasformed_test_y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matlab integration - KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(source_df,target_df):\n",
    "    mat_source_df = mat.double(source_df.values.T.tolist())\n",
    "    mat_target_df = mat.double(target_df.values.T.tolist())\n",
    "    X = eng.HDP_KS(mat_source_df,mat_target_df,nargout=4)\n",
    "    train_X,train_y = np.array(X[0]),np.array(X[1]).tolist()[0]\n",
    "    test_X,test_y = np.array(X[2]),np.array(X[3]).tolist()[0]\n",
    "    return train_X,train_y,test_X,test_y\n",
    "trasformed_train_X,trasformed_train_y,trasformed_test_X,trasformed_test_y = transform_data(source_df,target_df)\n",
    "train_df = pd.DataFrame(trasformed_train_X)\n",
    "train_df['Buggy'] = trasformed_train_y\n",
    "train_df = apply_smote(train_df)\n",
    "trasformed_train_y = train_df.Buggy\n",
    "trasformed_train_X = train_df.drop('Buggy',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.21      0.31        52\n",
      "         1.0       0.24      0.62      0.35        21\n",
      "\n",
      "    accuracy                           0.33        73\n",
      "   macro avg       0.41      0.42      0.33        73\n",
      "weighted avg       0.48      0.33      0.32        73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suvodeepmajumder/Conda/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(trasformed_train_X,trasformed_train_y)\n",
    "predicted = clf.predict(trasformed_test_X)\n",
    "print(classification_report(trasformed_test_y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teting using original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(source_df,target_df):\n",
    "    train_y = source_df.Buggy\n",
    "    train_X = source_df.drop('Buggy',axis = 1)\n",
    "    test_y = target_df.Buggy\n",
    "    test_X = target_df.drop('Buggy',axis = 1)\n",
    "    return train_X,train_y,test_X,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_y,test_X,test_y = get_train_test_data(source_df,target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_X,train_y)\n",
    "predicted = clf.predict(test_X)\n",
    "print(classification_report(test_y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[train_y == True].shape,train_y[train_y == False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[test_y == True].shape,test_y[test_y == False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

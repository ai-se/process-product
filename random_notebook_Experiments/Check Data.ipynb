{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "import matlab.engine as engi\n",
    "import matlab as mat\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,roc_auc_score,recall_score,precision_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import CFS\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project):\n",
    "    understand_path = 'data/understand_files/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "#     print(understand_df)\n",
    "#     understand_df = understand_df.drop(['Kind','Name'],axis = 1)\n",
    "#     understand_df = understand_df[['Bugs', 'Name', 'commit_hash', 'AvgCyclomatic', 'AvgCyclomaticModified',\n",
    "#        'AvgCyclomaticStrict', 'AvgEssential', 'AvgLine', 'AvgLineBlank',\n",
    "#        'AvgLineCode', 'AvgLineComment', 'CountClassBase', 'CountClassCoupled',\n",
    "#        'CountClassCoupledModified', 'CountClassDerived',\n",
    "#        'CountDeclClassMethod', 'CountDeclClassVariable',\n",
    "#        'CountDeclInstanceMethod', 'CountDeclInstanceVariable',\n",
    "#        'CountDeclMethod', 'CountDeclMethodAll', 'CountDeclMethodDefault',\n",
    "#        'CountDeclMethodPrivate', 'CountDeclMethodProtected',\n",
    "#        'CountDeclMethodPublic', 'CountLine', 'CountLineBlank', 'CountLineCode',\n",
    "#        'CountLineCodeDecl', 'CountLineCodeExe', 'CountLineComment',\n",
    "#        'CountSemicolon', 'CountStmt', 'CountStmtDecl', 'CountStmtExe',\n",
    "#        'MaxCyclomatic', 'MaxCyclomaticModified', 'MaxCyclomaticStrict',\n",
    "#        'MaxEssential', 'MaxInheritanceTree', 'MaxNesting',\n",
    "#        'PercentLackOfCohesion', 'PercentLackOfCohesionModified',\n",
    "#        'RatioCommentToCode', 'SumCyclomatic', 'SumCyclomaticModified',\n",
    "#        'SumCyclomaticStrict', 'SumEssential']]\n",
    "\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    cols = understand_df.columns.tolist()\n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['parent_hashes','author_name','author_name',\n",
    "                                                   'author_email','fileschanged','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix', 'contains_bug','fixes',],axis=1)\n",
    "    \n",
    "#     print(cols[3:len(cols)-2])\n",
    "#     print(understand_df.shape)\n",
    "    understand_df = understand_df.drop_duplicates(cols[3:len(cols)-2])\n",
    "#     print(understand_df.shape)\n",
    "    df = understand_df.merge(commit_guru_df,on='commit_hash')\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "#     print(df.columns)\n",
    "    df = df.drop(labels = ['Kind','Name','commit_hash'],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "#     df,cols = apply_cfs(df)\n",
    "    y = df.Bugs\n",
    "    X = df.drop('Bugs',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "#     X = X.drop(labels = ['la', 'ld', 'nf', 'ns', 'nd',\n",
    "#        'entrophy', 'ndev', 'lt', 'nuc', 'age', 'exp', 'rexp', 'sexp'], axis = 1)\n",
    "    return X,y\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "        y = df.Bugs.values\n",
    "        X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "        X = X.values\n",
    "        selected_cols = CFS.cfs(X,y)\n",
    "        cols = df.columns[[selected_cols]].tolist()\n",
    "        cols.append('Bugs')\n",
    "        return df[cols],cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_self(project):\n",
    "    X,y = load_data(project)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "    df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "    df_smote = apply_smote(df_smote)\n",
    "    y_train = df_smote.Bugs\n",
    "    X_train = df_smote.drop('Bugs',axis = 1)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print(classification_report(y_test, predicted))\n",
    "    recall = recall_score(y_test, predicted,average='binary')\n",
    "    precision = precision_score(y_test, predicted,average='binary')\n",
    "    return recall,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = 'data/understand_files/'\n",
    "projects = [f.split('_understand')[0] for f in listdir(_dir) if isfile(join(_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++   metacat  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74       377\n",
      "           1       0.78      0.83      0.80       455\n",
      "\n",
      "    accuracy                           0.78       832\n",
      "   macro avg       0.77      0.77      0.77       832\n",
      "weighted avg       0.78      0.78      0.77       832\n",
      "\n",
      "0.7699507389162561\n",
      "+++++++++++++++++   phoenicis  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   vim.js  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n",
      "+++++++++++++++++   loklak_wok_android  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.50      0.56        32\n",
      "           1       0.71      0.82      0.76        49\n",
      "\n",
      "    accuracy                           0.69        81\n",
      "   macro avg       0.68      0.66      0.66        81\n",
      "weighted avg       0.68      0.69      0.68        81\n",
      "\n",
      "0.6581632653061225\n",
      "+++++++++++++++++   scoop  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.87        67\n",
      "           1       0.48      0.80      0.60        15\n",
      "\n",
      "    accuracy                           0.80        82\n",
      "   macro avg       0.71      0.80      0.74        82\n",
      "weighted avg       0.86      0.80      0.82        82\n",
      "\n",
      "0.8029850746268657\n",
      "+++++++++++++++++   proxygen  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.93      1886\n",
      "           1       0.09      0.74      0.16        34\n",
      "\n",
      "    accuracy                           0.86      1920\n",
      "   macro avg       0.54      0.80      0.54      1920\n",
      "weighted avg       0.98      0.86      0.91      1920\n",
      "\n",
      "0.8000436653982909\n",
      "+++++++++++++++++   jinja2  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   cassandra-lucene-index  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.75      0.64       548\n",
      "           1       0.88      0.76      0.82      1328\n",
      "\n",
      "    accuracy                           0.76      1876\n",
      "   macro avg       0.72      0.75      0.73      1876\n",
      "weighted avg       0.79      0.76      0.76      1876\n",
      "\n",
      "0.7530697607950049\n",
      "+++++++++++++++++   arara  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88        34\n",
      "           1       0.96      0.88      0.92        60\n",
      "\n",
      "    accuracy                           0.90        94\n",
      "   macro avg       0.89      0.91      0.90        94\n",
      "weighted avg       0.91      0.90      0.91        94\n",
      "\n",
      "0.9122549019607843\n",
      "+++++++++++++++++   UpdateChecker  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.60      0.55        10\n",
      "           1       0.56      0.45      0.50        11\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.53      0.53      0.52        21\n",
      "weighted avg       0.53      0.52      0.52        21\n",
      "\n",
      "0.5272727272727272\n",
      "+++++++++++++++++   zipline  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      2924\n",
      "           1       0.15      1.00      0.26         4\n",
      "\n",
      "    accuracy                           0.99      2928\n",
      "   macro avg       0.57      1.00      0.63      2928\n",
      "weighted avg       1.00      0.99      1.00      2928\n",
      "\n",
      "0.9960670314637483\n",
      "+++++++++++++++++   eo  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.64      0.56        22\n",
      "           1       0.78      0.67      0.72        42\n",
      "\n",
      "    accuracy                           0.66        64\n",
      "   macro avg       0.64      0.65      0.64        64\n",
      "weighted avg       0.68      0.66      0.66        64\n",
      "\n",
      "0.6515151515151515\n",
      "+++++++++++++++++   rxjava-jdbc  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       229\n",
      "           1       0.69      0.76      0.72       161\n",
      "\n",
      "    accuracy                           0.76       390\n",
      "   macro avg       0.75      0.76      0.75       390\n",
      "weighted avg       0.76      0.76      0.76       390\n",
      "\n",
      "0.7587946513330982\n",
      "+++++++++++++++++   polyglot  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66        40\n",
      "           1       0.85      0.83      0.84        89\n",
      "\n",
      "    accuracy                           0.78       129\n",
      "   macro avg       0.75      0.75      0.75       129\n",
      "weighted avg       0.79      0.78      0.78       129\n",
      "\n",
      "0.7532303370786517\n",
      "+++++++++++++++++   easygcm  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90         9\n",
      "           1       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.92        24\n",
      "   macro avg       0.91      0.93      0.91        24\n",
      "weighted avg       0.93      0.92      0.92        24\n",
      "\n",
      "0.9333333333333333\n",
      "+++++++++++++++++   Much-Assembly-Required  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       215\n",
      "           1       0.75      0.74      0.75       254\n",
      "\n",
      "    accuracy                           0.73       469\n",
      "   macro avg       0.73      0.73      0.73       469\n",
      "weighted avg       0.73      0.73      0.73       469\n",
      "\n",
      "0.7262497711041934\n",
      "+++++++++++++++++   Elephant  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78       350\n",
      "           1       0.61      0.75      0.67       200\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.72      0.74      0.72       550\n",
      "weighted avg       0.75      0.73      0.74       550\n",
      "\n",
      "0.7378571428571429\n",
      "+++++++++++++++++   Discord4J  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.62       886\n",
      "           1       0.78      0.68      0.72      1448\n",
      "\n",
      "    accuracy                           0.68      2334\n",
      "   macro avg       0.67      0.68      0.67      2334\n",
      "weighted avg       0.70      0.68      0.69      2334\n",
      "\n",
      "0.6842083109886137\n",
      "+++++++++++++++++   RxJavaFX  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        47\n",
      "           1       0.64      0.84      0.73        19\n",
      "\n",
      "    accuracy                           0.82        66\n",
      "   macro avg       0.78      0.83      0.80        66\n",
      "weighted avg       0.84      0.82      0.82        66\n",
      "\n",
      "0.8253079507278837\n",
      "+++++++++++++++++   Sudachi  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64       103\n",
      "           1       0.75      0.71      0.73       146\n",
      "\n",
      "    accuracy                           0.69       249\n",
      "   macro avg       0.68      0.69      0.68       249\n",
      "weighted avg       0.69      0.69      0.69       249\n",
      "\n",
      "0.6862614709402846\n",
      "+++++++++++++++++   dropwizard  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69      1193\n",
      "           1       0.69      0.66      0.67      1198\n",
      "\n",
      "    accuracy                           0.68      2391\n",
      "   macro avg       0.68      0.68      0.68      2391\n",
      "weighted avg       0.68      0.68      0.68      2391\n",
      "\n",
      "0.6792551710240735\n",
      "+++++++++++++++++   ion-java  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       218\n",
      "           1       0.74      0.75      0.75       144\n",
      "\n",
      "    accuracy                           0.80       362\n",
      "   macro avg       0.79      0.79      0.79       362\n",
      "weighted avg       0.80      0.80      0.80       362\n",
      "\n",
      "0.7901376146788991\n",
      "+++++++++++++++++   Android-ObservableScrollView  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.73      0.78       187\n",
      "           1       0.50      0.68      0.57        74\n",
      "\n",
      "    accuracy                           0.71       261\n",
      "   macro avg       0.67      0.70      0.68       261\n",
      "weighted avg       0.75      0.71      0.72       261\n",
      "\n",
      "0.7014742014742015\n",
      "+++++++++++++++++   vulnerability-assessment-tool  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       342\n",
      "           1       0.86      0.91      0.89       464\n",
      "\n",
      "    accuracy                           0.87       806\n",
      "   macro avg       0.87      0.86      0.86       806\n",
      "weighted avg       0.87      0.87      0.87       806\n",
      "\n",
      "0.8582501512401693\n",
      "+++++++++++++++++   mopidy  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   pojobuilder  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.66       185\n",
      "           1       0.81      0.82      0.82       337\n",
      "\n",
      "    accuracy                           0.76       522\n",
      "   macro avg       0.74      0.73      0.74       522\n",
      "weighted avg       0.76      0.76      0.76       522\n",
      "\n",
      "0.734084529633491\n",
      "+++++++++++++++++   greenDAO  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n",
      "+++++++++++++++++   mezzanine  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   dcevm  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        72\n",
      "           1       0.88      0.83      0.85        42\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.89       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "0.8819444444444445\n",
      "+++++++++++++++++   freeline  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        53\n",
      "           1       0.72      0.72      0.72        39\n",
      "\n",
      "    accuracy                           0.76        92\n",
      "   macro avg       0.76      0.76      0.76        92\n",
      "weighted avg       0.76      0.76      0.76        92\n",
      "\n",
      "0.7552007740686987\n",
      "+++++++++++++++++   guice  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.82      0.86      3108\n",
      "           1       0.69      0.80      0.74      1538\n",
      "\n",
      "    accuracy                           0.82      4646\n",
      "   macro avg       0.79      0.81      0.80      4646\n",
      "weighted avg       0.83      0.82      0.82      4646\n",
      "\n",
      "0.8125214430481011\n",
      "+++++++++++++++++   react-native-background-job  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.71      0.61        14\n",
      "           1       0.43      0.25      0.32        12\n",
      "\n",
      "    accuracy                           0.50        26\n",
      "   macro avg       0.48      0.48      0.46        26\n",
      "weighted avg       0.48      0.50      0.47        26\n",
      "\n",
      "0.48214285714285715\n",
      "+++++++++++++++++   chunky  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       795\n",
      "           1       0.82      0.81      0.82       830\n",
      "\n",
      "    accuracy                           0.81      1625\n",
      "   macro avg       0.81      0.81      0.81      1625\n",
      "weighted avg       0.81      0.81      0.81      1625\n",
      "\n",
      "0.8142797605516405\n",
      "+++++++++++++++++   sofa-tracer  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       232\n",
      "           1       0.54      0.63      0.58        89\n",
      "\n",
      "    accuracy                           0.75       321\n",
      "   macro avg       0.70      0.71      0.70       321\n",
      "weighted avg       0.76      0.75      0.76       321\n",
      "\n",
      "0.7133136381247579\n",
      "+++++++++++++++++   Telegram-FOSS  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90      5615\n",
      "           1       0.71      0.81      0.76      2184\n",
      "\n",
      "    accuracy                           0.85      7799\n",
      "   macro avg       0.82      0.84      0.83      7799\n",
      "weighted avg       0.86      0.85      0.86      7799\n",
      "\n",
      "0.8412201259707938\n",
      "+++++++++++++++++   clean-status-bar  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        30\n",
      "           1       0.55      0.50      0.52        12\n",
      "\n",
      "    accuracy                           0.74        42\n",
      "   macro avg       0.68      0.67      0.67        42\n",
      "weighted avg       0.73      0.74      0.73        42\n",
      "\n",
      "0.6666666666666666\n",
      "+++++++++++++++++   EclipseCodeFormatter  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       104\n",
      "           1       0.79      0.77      0.78        90\n",
      "\n",
      "    accuracy                           0.80       194\n",
      "   macro avg       0.80      0.80      0.80       194\n",
      "weighted avg       0.80      0.80      0.80       194\n",
      "\n",
      "0.7967948717948717\n",
      "+++++++++++++++++   TrebleShot  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79      1326\n",
      "           1       0.68      0.74      0.71       880\n",
      "\n",
      "    accuracy                           0.76      2206\n",
      "   macro avg       0.75      0.75      0.75      2206\n",
      "weighted avg       0.76      0.76      0.76      2206\n",
      "\n",
      "0.7537527423556836\n",
      "+++++++++++++++++   Faker  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   SoLoader  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77        39\n",
      "           1       0.37      0.64      0.47        11\n",
      "\n",
      "    accuracy                           0.68        50\n",
      "   macro avg       0.62      0.66      0.62        50\n",
      "weighted avg       0.76      0.68      0.70        50\n",
      "\n",
      "0.6643356643356643\n",
      "+++++++++++++++++   digdag  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70      1280\n",
      "           1       0.62      0.67      0.65       989\n",
      "\n",
      "    accuracy                           0.68      2269\n",
      "   macro avg       0.67      0.68      0.68      2269\n",
      "weighted avg       0.68      0.68      0.68      2269\n",
      "\n",
      "0.6774436773255813\n",
      "+++++++++++++++++   jedis  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       619\n",
      "           1       0.67      0.62      0.64       487\n",
      "\n",
      "    accuracy                           0.70      1106\n",
      "   macro avg       0.69      0.69      0.69      1106\n",
      "weighted avg       0.70      0.70      0.70      1106\n",
      "\n",
      "0.690076064925544\n",
      "+++++++++++++++++   Material-Calendar-View  +++++++++++++++++\n",
      "Found array with 0 sample(s) (shape=(0, 58)) while a minimum of 1 is required by MinMaxScaler.\n",
      "+++++++++++++++++   uhabits  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       722\n",
      "           1       0.74      0.72      0.73       844\n",
      "\n",
      "    accuracy                           0.71      1566\n",
      "   macro avg       0.71      0.71      0.71      1566\n",
      "weighted avg       0.71      0.71      0.71      1566\n",
      "\n",
      "0.7094202518018669\n",
      "+++++++++++++++++   metrics  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.72       617\n",
      "           1       0.58      0.64      0.61       417\n",
      "\n",
      "    accuracy                           0.67      1034\n",
      "   macro avg       0.66      0.67      0.66      1034\n",
      "weighted avg       0.68      0.67      0.67      1034\n",
      "\n",
      "0.6657843903159483\n",
      "+++++++++++++++++   openrouteservice  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       864\n",
      "           1       0.81      0.73      0.77      1412\n",
      "\n",
      "    accuracy                           0.73      2276\n",
      "   macro avg       0.72      0.73      0.72      2276\n",
      "weighted avg       0.74      0.73      0.73      2276\n",
      "\n",
      "0.7259370737593117\n",
      "+++++++++++++++++   parquet-mr  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1228\n",
      "           1       0.64      0.73      0.68       797\n",
      "\n",
      "    accuracy                           0.73      2025\n",
      "   macro avg       0.72      0.73      0.73      2025\n",
      "weighted avg       0.74      0.73      0.74      2025\n",
      "\n",
      "0.7326032270852831\n",
      "+++++++++++++++++   druid  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       890\n",
      "           1       0.59      0.94      0.73       153\n",
      "\n",
      "    accuracy                           0.90      1043\n",
      "   macro avg       0.79      0.91      0.83      1043\n",
      "weighted avg       0.93      0.90      0.91      1043\n",
      "\n",
      "0.9149702577660278\n",
      "+++++++++++++++++   picasso  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       328\n",
      "           1       0.76      0.74      0.75       338\n",
      "\n",
      "    accuracy                           0.75       666\n",
      "   macro avg       0.75      0.75      0.75       666\n",
      "weighted avg       0.75      0.75      0.75       666\n",
      "\n",
      "0.7478712656949055\n",
      "+++++++++++++++++   react-native-screens  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        18\n",
      "           1       1.00      0.86      0.92        21\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.93      0.93      0.92        39\n",
      "weighted avg       0.93      0.92      0.92        39\n",
      "\n",
      "0.9285714285714286\n",
      "+++++++++++++++++   truetime-android  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73        32\n",
      "           1       0.70      0.79      0.74        29\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.74      0.74      0.74        61\n",
      "weighted avg       0.74      0.74      0.74        61\n",
      "\n",
      "0.740301724137931\n",
      "+++++++++++++++++   android-test  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       397\n",
      "           1       0.74      0.77      0.76       287\n",
      "\n",
      "    accuracy                           0.79       684\n",
      "   macro avg       0.79      0.79      0.79       684\n",
      "weighted avg       0.79      0.79      0.79       684\n",
      "\n",
      "0.789782251906722\n",
      "+++++++++++++++++   android-ago  +++++++++++++++++\n",
      "index 1 is out of bounds for axis 0 with size 1\n",
      "+++++++++++++++++   springside4  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69       469\n",
      "           1       0.72      0.73      0.73       519\n",
      "\n",
      "    accuracy                           0.71       988\n",
      "   macro avg       0.71      0.71      0.71       988\n",
      "weighted avg       0.71      0.71      0.71       988\n",
      "\n",
      "0.7103356052109395\n",
      "+++++++++++++++++   pacbot  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       512\n",
      "           1       0.36      0.56      0.43         9\n",
      "\n",
      "    accuracy                           0.98       521\n",
      "   macro avg       0.67      0.77      0.71       521\n",
      "weighted avg       0.98      0.98      0.98       521\n",
      "\n",
      "0.7689887152777778\n",
      "+++++++++++++++++   subclipse  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       852\n",
      "           1       0.51      0.62      0.56       376\n",
      "\n",
      "    accuracy                           0.70      1228\n",
      "   macro avg       0.66      0.68      0.66      1228\n",
      "weighted avg       0.72      0.70      0.71      1228\n",
      "\n",
      "0.6767805414044551\n",
      "+++++++++++++++++   Hystrix  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91      2452\n",
      "           1       0.51      0.77      0.62       442\n",
      "\n",
      "    accuracy                           0.85      2894\n",
      "   macro avg       0.73      0.82      0.76      2894\n",
      "weighted avg       0.89      0.85      0.86      2894\n",
      "\n",
      "0.8182313080835295\n",
      "+++++++++++++++++   postgres-async-driver  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66        94\n",
      "           1       0.80      0.68      0.73       142\n",
      "\n",
      "    accuracy                           0.70       236\n",
      "   macro avg       0.70      0.71      0.70       236\n",
      "weighted avg       0.72      0.70      0.71       236\n",
      "\n",
      "0.7085705723703926\n",
      "+++++++++++++++++   jboss-eap-quickstarts  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.80      0.64       183\n",
      "           1       0.89      0.70      0.79       420\n",
      "\n",
      "    accuracy                           0.73       603\n",
      "   macro avg       0.71      0.75      0.72       603\n",
      "weighted avg       0.78      0.73      0.74       603\n",
      "\n",
      "0.7512880562060891\n",
      "+++++++++++++++++   app-icon  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   moditect  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84       116\n",
      "           1       0.26      0.47      0.34        19\n",
      "\n",
      "    accuracy                           0.74       135\n",
      "   macro avg       0.58      0.63      0.59       135\n",
      "weighted avg       0.81      0.74      0.77       135\n",
      "\n",
      "0.6290834845735028\n",
      "+++++++++++++++++   manifold  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       515\n",
      "           1       0.62      0.59      0.61       409\n",
      "\n",
      "    accuracy                           0.66       924\n",
      "   macro avg       0.66      0.66      0.66       924\n",
      "weighted avg       0.66      0.66      0.66       924\n",
      "\n",
      "0.6553184418543927\n",
      "+++++++++++++++++   progressbar  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.83      0.90      0.86        21\n",
      "\n",
      "    accuracy                           0.81        31\n",
      "   macro avg       0.79      0.75      0.77        31\n",
      "weighted avg       0.80      0.81      0.80        31\n",
      "\n",
      "0.7523809523809524\n",
      "+++++++++++++++++   ActionBarSherlock  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84      1002\n",
      "           1       0.44      0.64      0.52       249\n",
      "\n",
      "    accuracy                           0.76      1251\n",
      "   macro avg       0.67      0.72      0.68      1251\n",
      "weighted avg       0.81      0.76      0.78      1251\n",
      "\n",
      "0.7189897313806124\n",
      "+++++++++++++++++   material-remixer-android  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.59        96\n",
      "           1       0.73      0.65      0.69       144\n",
      "\n",
      "    accuracy                           0.65       240\n",
      "   macro avg       0.64      0.65      0.64       240\n",
      "weighted avg       0.66      0.65      0.65       240\n",
      "\n",
      "0.6458333333333333\n",
      "+++++++++++++++++   nzbhydra2  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65       523\n",
      "           1       0.80      0.74      0.77       900\n",
      "\n",
      "    accuracy                           0.72      1423\n",
      "   macro avg       0.71      0.71      0.71      1423\n",
      "weighted avg       0.73      0.72      0.73      1423\n",
      "\n",
      "0.7148789037603569\n",
      "+++++++++++++++++   pyston  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   spring-javaformat  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        72\n",
      "           1       0.71      0.64      0.67        42\n",
      "\n",
      "    accuracy                           0.77       114\n",
      "   macro avg       0.76      0.75      0.75       114\n",
      "weighted avg       0.77      0.77      0.77       114\n",
      "\n",
      "0.7450396825396826\n",
      "+++++++++++++++++   iceberg  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       418\n",
      "           1       0.54      0.57      0.56       138\n",
      "\n",
      "    accuracy                           0.77       556\n",
      "   macro avg       0.70      0.71      0.70       556\n",
      "weighted avg       0.78      0.77      0.78       556\n",
      "\n",
      "0.7060883433881144\n",
      "+++++++++++++++++   sqlite-android  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93        61\n",
      "           1       0.36      0.80      0.50         5\n",
      "\n",
      "    accuracy                           0.88        66\n",
      "   macro avg       0.67      0.84      0.72        66\n",
      "weighted avg       0.93      0.88      0.90        66\n",
      "\n",
      "0.8426229508196721\n",
      "+++++++++++++++++   facebook-android-sdk  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75      1281\n",
      "           1       0.59      0.64      0.61       795\n",
      "\n",
      "    accuracy                           0.69      2076\n",
      "   macro avg       0.68      0.68      0.68      2076\n",
      "weighted avg       0.70      0.69      0.70      2076\n",
      "\n",
      "0.6827979320401218\n",
      "+++++++++++++++++   beets  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   swipe-button  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        20\n",
      "           1       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.89      0.95      0.91        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "0.9500000000000001\n",
      "+++++++++++++++++   fdb-record-layer  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.80       863\n",
      "           1       0.53      0.67      0.59       363\n",
      "\n",
      "    accuracy                           0.73      1226\n",
      "   macro avg       0.69      0.71      0.69      1226\n",
      "weighted avg       0.75      0.73      0.74      1226\n",
      "\n",
      "0.7113040230600538\n",
      "+++++++++++++++++   heroic  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78      1791\n",
      "           1       0.68      0.76      0.72      1260\n",
      "\n",
      "    accuracy                           0.75      3051\n",
      "   macro avg       0.75      0.75      0.75      3051\n",
      "weighted avg       0.76      0.75      0.75      3051\n",
      "\n",
      "0.7529731993299832\n",
      "+++++++++++++++++   cyclops-integration  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.61      0.61       803\n",
      "           1       0.65      0.66      0.66       887\n",
      "\n",
      "    accuracy                           0.64      1690\n",
      "   macro avg       0.64      0.64      0.64      1690\n",
      "weighted avg       0.64      0.64      0.64      1690\n",
      "\n",
      "0.6352558963638328\n",
      "+++++++++++++++++   inbox  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   qbit  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.72      0.63       896\n",
      "           1       0.79      0.66      0.72      1472\n",
      "\n",
      "    accuracy                           0.68      2368\n",
      "   macro avg       0.68      0.69      0.67      2368\n",
      "weighted avg       0.70      0.68      0.68      2368\n",
      "\n",
      "0.6868449145962733\n",
      "+++++++++++++++++   nakadi  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58       856\n",
      "           1       0.71      0.66      0.69      1243\n",
      "\n",
      "    accuracy                           0.64      2099\n",
      "   macro avg       0.63      0.64      0.63      2099\n",
      "weighted avg       0.65      0.64      0.64      2099\n",
      "\n",
      "0.6370901346606417\n",
      "+++++++++++++++++   OpenRefine  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74      1784\n",
      "           1       0.70      0.73      0.71      1577\n",
      "\n",
      "    accuracy                           0.73      3361\n",
      "   macro avg       0.73      0.73      0.73      3361\n",
      "weighted avg       0.73      0.73      0.73      3361\n",
      "\n",
      "0.7268203093232026\n",
      "+++++++++++++++++   jBrowserDriver  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       402\n",
      "           1       0.78      0.77      0.77       371\n",
      "\n",
      "    accuracy                           0.78       773\n",
      "   macro avg       0.78      0.78      0.78       773\n",
      "weighted avg       0.78      0.78      0.78       773\n",
      "\n",
      "0.7834546941840661\n",
      "+++++++++++++++++   MaterialScrollBar  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        57\n",
      "           1       0.69      0.73      0.71        45\n",
      "\n",
      "    accuracy                           0.74       102\n",
      "   macro avg       0.73      0.74      0.73       102\n",
      "weighted avg       0.74      0.74      0.74       102\n",
      "\n",
      "0.7350877192982457\n",
      "+++++++++++++++++   react-native-dialogs  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84         9\n",
      "           1       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.84      0.83      0.83        18\n",
      "weighted avg       0.84      0.83      0.83        18\n",
      "\n",
      "0.8333333333333333\n",
      "+++++++++++++++++   roboguice  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86      1068\n",
      "           1       0.50      0.88      0.64       272\n",
      "\n",
      "    accuracy                           0.80      1340\n",
      "   macro avg       0.73      0.83      0.75      1340\n",
      "weighted avg       0.87      0.80      0.82      1340\n",
      "\n",
      "0.8270131086142323\n",
      "+++++++++++++++++   tweepy  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   disruptor  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       326\n",
      "           1       0.75      0.76      0.75       332\n",
      "\n",
      "    accuracy                           0.75       658\n",
      "   macro avg       0.75      0.75      0.75       658\n",
      "weighted avg       0.75      0.75      0.75       658\n",
      "\n",
      "0.7507114346958387\n",
      "+++++++++++++++++   s3proxy  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       102\n",
      "           1       0.77      0.62      0.69       108\n",
      "\n",
      "    accuracy                           0.71       210\n",
      "   macro avg       0.72      0.71      0.71       210\n",
      "weighted avg       0.72      0.71      0.71       210\n",
      "\n",
      "0.7121459694989106\n",
      "+++++++++++++++++   JSONassert  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65        19\n",
      "           1       0.71      0.55      0.62        22\n",
      "\n",
      "    accuracy                           0.63        41\n",
      "   macro avg       0.64      0.64      0.63        41\n",
      "weighted avg       0.65      0.63      0.63        41\n",
      "\n",
      "0.6411483253588517\n",
      "+++++++++++++++++   macrobase  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.59      0.50       179\n",
      "           1       0.82      0.72      0.76       472\n",
      "\n",
      "    accuracy                           0.68       651\n",
      "   macro avg       0.63      0.65      0.63       651\n",
      "weighted avg       0.72      0.68      0.69       651\n",
      "\n",
      "0.651346936843102\n",
      "+++++++++++++++++   jsoup  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77       547\n",
      "           1       0.71      0.81      0.75       455\n",
      "\n",
      "    accuracy                           0.76      1002\n",
      "   macro avg       0.76      0.77      0.76      1002\n",
      "weighted avg       0.77      0.76      0.76      1002\n",
      "\n",
      "0.7652711091467947\n",
      "+++++++++++++++++   java-object-diff  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       171\n",
      "           1       0.79      0.70      0.74       213\n",
      "\n",
      "    accuracy                           0.73       384\n",
      "   macro avg       0.73      0.74      0.73       384\n",
      "weighted avg       0.74      0.73      0.73       384\n",
      "\n",
      "0.7351536117288526\n",
      "+++++++++++++++++   getdown  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.78      0.69       152\n",
      "           1       0.83      0.71      0.76       238\n",
      "\n",
      "    accuracy                           0.73       390\n",
      "   macro avg       0.73      0.74      0.73       390\n",
      "weighted avg       0.75      0.73      0.74       390\n",
      "\n",
      "0.7410990712074303\n",
      "+++++++++++++++++   newspaper  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   How-to-Make-a-Computer-Operating-System  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n",
      "+++++++++++++++++   SpringCloud  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.72       106\n",
      "           1       0.46      0.49      0.47        53\n",
      "\n",
      "    accuracy                           0.64       159\n",
      "   macro avg       0.60      0.60      0.60       159\n",
      "weighted avg       0.64      0.64      0.64       159\n",
      "\n",
      "0.5990566037735848\n",
      "+++++++++++++++++   Telegram  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      4952\n",
      "           1       0.67      0.81      0.74      2118\n",
      "\n",
      "    accuracy                           0.83      7070\n",
      "   macro avg       0.79      0.82      0.80      7070\n",
      "weighted avg       0.84      0.83      0.83      7070\n",
      "\n",
      "0.8221720776298548\n",
      "+++++++++++++++++   hollow  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81       765\n",
      "           1       0.53      0.44      0.48       305\n",
      "\n",
      "    accuracy                           0.73      1070\n",
      "   macro avg       0.66      0.64      0.65      1070\n",
      "weighted avg       0.72      0.73      0.72      1070\n",
      "\n",
      "0.6415729133183328\n",
      "+++++++++++++++++   Digital  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      2462\n",
      "           1       0.61      0.68      0.65      1483\n",
      "\n",
      "    accuracy                           0.72      3945\n",
      "   macro avg       0.70      0.71      0.71      3945\n",
      "weighted avg       0.73      0.72      0.72      3945\n",
      "\n",
      "0.7110175818770326\n",
      "+++++++++++++++++   signal-cli  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        78\n",
      "           1       0.74      0.85      0.79        66\n",
      "\n",
      "    accuracy                           0.79       144\n",
      "   macro avg       0.79      0.80      0.79       144\n",
      "weighted avg       0.80      0.79      0.79       144\n",
      "\n",
      "0.7960372960372961\n",
      "+++++++++++++++++   gunicorn  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   powerline  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   fragmentargs  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.20      0.13         5\n",
      "           1       0.78      0.61      0.68        23\n",
      "\n",
      "    accuracy                           0.54        28\n",
      "   macro avg       0.44      0.40      0.41        28\n",
      "weighted avg       0.66      0.54      0.58        28\n",
      "\n",
      "0.4043478260869565\n",
      "+++++++++++++++++   intellij-plugin-save-actions  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.78        84\n",
      "           1       0.73      0.76      0.74        70\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.76      0.76      0.76       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n",
      "0.7595238095238095\n",
      "+++++++++++++++++   dns66  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        80\n",
      "           1       0.50      0.46      0.48        28\n",
      "\n",
      "    accuracy                           0.74       108\n",
      "   macro avg       0.66      0.65      0.65       108\n",
      "weighted avg       0.73      0.74      0.74       108\n",
      "\n",
      "0.6508928571428572\n",
      "+++++++++++++++++   blueflood  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71       827\n",
      "           1       0.61      0.66      0.64       615\n",
      "\n",
      "    accuracy                           0.68      1442\n",
      "   macro avg       0.67      0.68      0.67      1442\n",
      "weighted avg       0.68      0.68      0.68      1442\n",
      "\n",
      "0.6759095958553297\n",
      "+++++++++++++++++   intellij-elixir  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      1108\n",
      "           1       0.73      0.68      0.71      1176\n",
      "\n",
      "    accuracy                           0.71      2284\n",
      "   macro avg       0.71      0.71      0.71      2284\n",
      "weighted avg       0.71      0.71      0.71      2284\n",
      "\n",
      "0.7073602003978485\n",
      "+++++++++++++++++   nokogiri  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       454\n",
      "           1       0.80      0.75      0.78       390\n",
      "\n",
      "    accuracy                           0.80       844\n",
      "   macro avg       0.80      0.80      0.80       844\n",
      "weighted avg       0.80      0.80      0.80       844\n",
      "\n",
      "0.7965266011521518\n",
      "+++++++++++++++++   DaggerMock  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        90\n",
      "           1       0.39      0.32      0.35        28\n",
      "\n",
      "    accuracy                           0.72       118\n",
      "   macro avg       0.60      0.58      0.59       118\n",
      "weighted avg       0.70      0.72      0.71       118\n",
      "\n",
      "0.582936507936508\n",
      "+++++++++++++++++   peewee  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   AndroidAsync  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83       855\n",
      "           1       0.68      0.75      0.72       486\n",
      "\n",
      "    accuracy                           0.78      1341\n",
      "   macro avg       0.77      0.78      0.77      1341\n",
      "weighted avg       0.79      0.78      0.79      1341\n",
      "\n",
      "0.7762399826727312\n",
      "+++++++++++++++++   qpython  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   graphicsfuzz  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88       662\n",
      "           1       0.67      0.88      0.76       264\n",
      "\n",
      "    accuracy                           0.84       926\n",
      "   macro avg       0.81      0.85      0.82       926\n",
      "weighted avg       0.87      0.84      0.85       926\n",
      "\n",
      "0.8513972809667674\n",
      "+++++++++++++++++   pgjdbc-ng  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77       688\n",
      "           1       0.88      0.73      0.79       939\n",
      "\n",
      "    accuracy                           0.78      1627\n",
      "   macro avg       0.79      0.79      0.78      1627\n",
      "weighted avg       0.80      0.78      0.78      1627\n",
      "\n",
      "0.7921256222601977\n",
      "+++++++++++++++++   PushSharp  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n",
      "+++++++++++++++++   kafkahq  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74       102\n",
      "           1       0.65      0.55      0.59        73\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.68      0.67      0.67       175\n",
      "weighted avg       0.68      0.69      0.68       175\n",
      "\n",
      "0.666129465484824\n",
      "+++++++++++++++++   jieba  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   SuperListview  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63        11\n",
      "           1       0.38      0.60      0.46         5\n",
      "\n",
      "    accuracy                           0.56        16\n",
      "   macro avg       0.56      0.57      0.55        16\n",
      "weighted avg       0.63      0.56      0.58        16\n",
      "\n",
      "0.5727272727272728\n",
      "+++++++++++++++++   Grammar-Kit  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       662\n",
      "           1       0.60      0.71      0.65       327\n",
      "\n",
      "    accuracy                           0.75       989\n",
      "   macro avg       0.72      0.74      0.72       989\n",
      "weighted avg       0.76      0.75      0.75       989\n",
      "\n",
      "0.7361415227694781\n",
      "+++++++++++++++++   couchdb-lucene  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       266\n",
      "           1       0.69      0.67      0.68       212\n",
      "\n",
      "    accuracy                           0.72       478\n",
      "   macro avg       0.72      0.71      0.72       478\n",
      "weighted avg       0.72      0.72      0.72       478\n",
      "\n",
      "0.7146049084976592\n",
      "+++++++++++++++++   RustDT  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      2225\n",
      "           1       0.32      0.56      0.41       383\n",
      "\n",
      "    accuracy                           0.76      2608\n",
      "   macro avg       0.62      0.68      0.63      2608\n",
      "weighted avg       0.83      0.76      0.79      2608\n",
      "\n",
      "0.6793305365681932\n",
      "+++++++++++++++++   BiglyBT  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      3960\n",
      "           1       0.63      0.65      0.64      1568\n",
      "\n",
      "    accuracy                           0.79      5528\n",
      "   macro avg       0.75      0.75      0.75      5528\n",
      "weighted avg       0.80      0.79      0.80      5528\n",
      "\n",
      "0.7513379973201402\n",
      "+++++++++++++++++   archaius  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71       174\n",
      "           1       0.44      0.60      0.51        80\n",
      "\n",
      "    accuracy                           0.64       254\n",
      "   macro avg       0.61      0.63      0.61       254\n",
      "weighted avg       0.67      0.64      0.65       254\n",
      "\n",
      "0.6275862068965518\n",
      "+++++++++++++++++   jsweet  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77      1422\n",
      "           1       0.70      0.72      0.71      1096\n",
      "\n",
      "    accuracy                           0.75      2518\n",
      "   macro avg       0.74      0.74      0.74      2518\n",
      "weighted avg       0.75      0.75      0.75      2518\n",
      "\n",
      "0.7429990914410669\n",
      "+++++++++++++++++   thingsboard  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.67      0.65       859\n",
      "           1       0.75      0.71      0.73      1187\n",
      "\n",
      "    accuracy                           0.69      2046\n",
      "   macro avg       0.69      0.69      0.69      2046\n",
      "weighted avg       0.70      0.69      0.69      2046\n",
      "\n",
      "0.690431753385777\n",
      "+++++++++++++++++   amidst  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       915\n",
      "           1       0.67      0.65      0.66       849\n",
      "\n",
      "    accuracy                           0.68      1764\n",
      "   macro avg       0.68      0.68      0.68      1764\n",
      "weighted avg       0.68      0.68      0.68      1764\n",
      "\n",
      "0.678178763830157\n",
      "+++++++++++++++++   django-rest-framework  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   Cactus  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   rapidoid  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80      4616\n",
      "           1       0.51      0.61      0.56      1836\n",
      "\n",
      "    accuracy                           0.73      6452\n",
      "   macro avg       0.67      0.69      0.68      6452\n",
      "weighted avg       0.74      0.73      0.73      6452\n",
      "\n",
      "0.6899700954905359\n",
      "+++++++++++++++++   project-rome  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92        27\n",
      "           1       0.80      0.92      0.86        13\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.88      0.91      0.89        40\n",
      "weighted avg       0.91      0.90      0.90        40\n",
      "\n",
      "0.905982905982906\n",
      "+++++++++++++++++   zotfile  +++++++++++++++++\n",
      "'commit_hash'\n",
      "+++++++++++++++++   FreeBuilder  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       552\n",
      "           1       0.67      0.72      0.69       374\n",
      "\n",
      "    accuracy                           0.74       926\n",
      "   macro avg       0.73      0.74      0.74       926\n",
      "weighted avg       0.75      0.74      0.74       926\n",
      "\n",
      "0.7387235526621716\n",
      "+++++++++++++++++   Android-Orma  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       583\n",
      "           1       0.65      0.67      0.66       410\n",
      "\n",
      "    accuracy                           0.71       993\n",
      "   macro avg       0.70      0.71      0.71       993\n",
      "weighted avg       0.71      0.71      0.71       993\n",
      "\n",
      "0.7070827929548593\n",
      "+++++++++++++++++   android-transcoder  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.90      0.69        21\n",
      "           1       0.67      0.21      0.32        19\n",
      "\n",
      "    accuracy                           0.57        40\n",
      "   macro avg       0.61      0.56      0.51        40\n",
      "weighted avg       0.61      0.57      0.51        40\n",
      "\n",
      "0.5576441102756893\n",
      "+++++++++++++++++   taiga-back  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   androidannotations  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1268\n",
      "           1       0.73      0.76      0.74      1112\n",
      "\n",
      "    accuracy                           0.76      2380\n",
      "   macro avg       0.76      0.76      0.76      2380\n",
      "weighted avg       0.76      0.76      0.76      2380\n",
      "\n",
      "0.7566963779134419\n",
      "+++++++++++++++++   docker-compose-rule  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59       135\n",
      "           1       0.54      0.57      0.56       117\n",
      "\n",
      "    accuracy                           0.58       252\n",
      "   macro avg       0.57      0.58      0.57       252\n",
      "weighted avg       0.58      0.58      0.58       252\n",
      "\n",
      "0.5752136752136752\n",
      "+++++++++++++++++   pebble  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.77      0.65       427\n",
      "           1       0.85      0.68      0.76       802\n",
      "\n",
      "    accuracy                           0.71      1229\n",
      "   macro avg       0.71      0.73      0.70      1229\n",
      "weighted avg       0.75      0.71      0.72      1229\n",
      "\n",
      "0.7268917869261272\n",
      "+++++++++++++++++   tikxml  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        94\n",
      "           1       0.70      0.80      0.75        79\n",
      "\n",
      "    accuracy                           0.75       173\n",
      "   macro avg       0.75      0.76      0.75       173\n",
      "weighted avg       0.76      0.75      0.75       173\n",
      "\n",
      "0.7551171559385941\n",
      "+++++++++++++++++   coursera-android  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n",
      "+++++++++++++++++   seaborn  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   spectator  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       342\n",
      "           1       0.71      0.73      0.72       404\n",
      "\n",
      "    accuracy                           0.69       746\n",
      "   macro avg       0.69      0.69      0.69       746\n",
      "weighted avg       0.69      0.69      0.69       746\n",
      "\n",
      "0.6908980371721383\n",
      "+++++++++++++++++   phpinspectionsea  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.82      0.89      4020\n",
      "           1       0.40      0.87      0.55       558\n",
      "\n",
      "    accuracy                           0.82      4578\n",
      "   macro avg       0.69      0.84      0.72      4578\n",
      "weighted avg       0.91      0.82      0.85      4578\n",
      "\n",
      "0.8444645054298401\n",
      "+++++++++++++++++   thumbor  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   pyspider  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   react-native-sensitive-info  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        18\n",
      "           1       0.91      0.91      0.91        33\n",
      "\n",
      "    accuracy                           0.88        51\n",
      "   macro avg       0.87      0.87      0.87        51\n",
      "weighted avg       0.88      0.88      0.88        51\n",
      "\n",
      "0.8712121212121213\n",
      "+++++++++++++++++   derive4j  +++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86        72\n",
      "           1       0.92      0.96      0.94       148\n",
      "\n",
      "    accuracy                           0.91       220\n",
      "   macro avg       0.91      0.89      0.90       220\n",
      "weighted avg       0.91      0.91      0.91       220\n",
      "\n",
      "0.8894519519519519\n",
      "+++++++++++++++++   opsu  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       414\n",
      "           1       0.79      0.83      0.81       502\n",
      "\n",
      "    accuracy                           0.78       916\n",
      "   macro avg       0.78      0.78      0.78       916\n",
      "weighted avg       0.78      0.78      0.78       916\n",
      "\n",
      "0.778865215466636\n",
      "+++++++++++++++++   org.alloytools.alloy  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83       138\n",
      "           1       0.90      0.77      0.83       168\n",
      "\n",
      "    accuracy                           0.83       306\n",
      "   macro avg       0.83      0.84      0.83       306\n",
      "weighted avg       0.84      0.83      0.83       306\n",
      "\n",
      "0.8361801242236024\n",
      "+++++++++++++++++   XX-Net  +++++++++++++++++\n",
      "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
      "+++++++++++++++++   Easer  +++++++++++++++++\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70       547\n",
      "           1       0.78      0.75      0.77       742\n",
      "\n",
      "    accuracy                           0.74      1289\n",
      "   macro avg       0.73      0.74      0.73      1289\n",
      "weighted avg       0.74      0.74      0.74      1289\n",
      "\n",
      "0.7361570339563509\n",
      "+++++++++++++++++   dagger  +++++++++++++++++\n",
      "\"['Kind'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "precision = []\n",
    "recall = []\n",
    "for project in projects:\n",
    "    try:\n",
    "        if project == '.DS_Store':\n",
    "            continue\n",
    "    #     if project != 'guice':\n",
    "    #         continue\n",
    "        print(\"+++++++++++++++++   \"  + project + \"  +++++++++++++++++\")\n",
    "        r,p = run_self(project)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Recall')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(num=None, figsize = (12,4), facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(121)\n",
    "ax.boxplot(precision)\n",
    "ax.set_title('Precision',size = 15)\n",
    "ax = fig.add_subplot(122)\n",
    "ax.boxplot(recall)\n",
    "ax.set_title('Recall',size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Recall')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(recall)\n",
    "plt.ylabel('Recall',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

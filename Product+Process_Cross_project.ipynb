{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matlab.engine as engi\n",
    "import matlab as mat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,roc_auc_score,recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from pyearth import Earth\n",
    "\n",
    "from src import SMOTE\n",
    "from src import CFS\n",
    "from src import metrices_V2 as metrices\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from threading import Thread\n",
    "from multiprocessing import Queue\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadWithReturnValue(Thread):\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                 args=(), kwargs={}, Verbose=None):\n",
    "        Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "    def run(self):\n",
    "        #print(type(self._target))\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args,\n",
    "                                                **self._kwargs)\n",
    "    def join(self, *args):\n",
    "        Thread.join(self, *args)\n",
    "        return self._return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "    cols_list = understand_df.columns.values.tolist()\n",
    "    for item in ['Kind', 'Name','commit_hash', 'Bugs']:\n",
    "        if item in cols_list:\n",
    "            cols_list.remove(item)\n",
    "            cols_list.insert(0,item)\n",
    "    understand_df = understand_df[cols_list]\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    cols = understand_df.columns.tolist()\n",
    "    \n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['parent_hashes','author_name','author_name',\n",
    "                                                   'author_email','fileschanged','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix', 'contains_bug','fixes',],axis=1)\n",
    "\n",
    "    understand_df = understand_df.drop_duplicates(cols[4:len(cols)])\n",
    "    df = understand_df.merge(commit_guru_df,on='commit_hash')\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "    for item in ['Kind', 'Name','commit_hash']:\n",
    "        if item in cols:\n",
    "            df = df.drop(labels = [item],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv('data/converted/'+ project + '_understand.csv',index=False)\n",
    "    y = df.Bugs\n",
    "    X = df.drop('Bugs',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "    return X,y\n",
    "\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "        y = df.Bugs.values\n",
    "        X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "        X = X.values\n",
    "        selected_cols = CFS.cfs(X,y)\n",
    "        cols = df.columns[[selected_cols]].tolist()\n",
    "        cols.append('Bugs')\n",
    "        return df[cols],cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_self(project,projects):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    pf_list = []\n",
    "    f1_list = []\n",
    "    g_list = []\n",
    "    auc_list = []\n",
    "    pci_20_list = []\n",
    "    ifa_list = []\n",
    "    featue_importance = []\n",
    "    X_train,y_train = load_data(project)\n",
    "    df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "    df_smote = apply_smote(df_smote)\n",
    "    y_train = df_smote.Bugs\n",
    "    X_train = df_smote.drop('Bugs',axis = 1)\n",
    "    clf =  RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    importance = 0\n",
    "    for project in projects:\n",
    "        try:\n",
    "            X_test,y_test = load_data(project)\n",
    "            loc = X_test.CountLineCode\n",
    "            predicted = clf.predict(X_test)\n",
    "            abcd = metrices.measures(y_test,predicted,loc)\n",
    "            pf_list.append(abcd.get_pf())\n",
    "            recall_list.append(abcd.calculate_recall())\n",
    "            precision_list.append(abcd.calculate_precision())\n",
    "            f1_list.append(abcd.calculate_f1_score())\n",
    "            g_list.append(abcd.get_g_score())\n",
    "            pci_20_list.append(abcd.get_pci_20())\n",
    "            ifa_list.append(abcd.get_ifa())\n",
    "            try:\n",
    "                auc_list.append(roc_auc_score(y_test, predicted))\n",
    "            except:\n",
    "                precision_list.append(0)\n",
    "        except:\n",
    "            continue\n",
    "    return np.nanmedian(recall_list),np.nanmedian(precision_list),np.nanmedian(pf_list),np.nanmedian(f1_list),np.nanmedian(g_list),np.nanmedian(auc_list),np.nanmedian(pci_20_list),np.nanmedian(ifa_list),importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self_CFS(project):\n",
    "    X,y = load_data(project)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "    loc = X_test.CountLineCode\n",
    "    df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "    df_smote = apply_smote(df_smote)\n",
    "    df_smote,cols = apply_cfs(df_smote)\n",
    "    y_train = df_smote.Bugs\n",
    "    X_train = df_smote.drop('Bugs',axis = 1)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    importance = clf.feature_importances_\n",
    "    predicted = clf.predict(X_test[cols[:-1]])\n",
    "    abcd = metrices.measures(y_test,predicted,loc)\n",
    "    pf = abcd.get_pf()\n",
    "    recall = abcd.calculate_recall()\n",
    "    precision = abcd.calculate_precision()\n",
    "    f1 = abcd.calculate_f1_score()\n",
    "    g_score = abcd.get_g_score()\n",
    "    pci_20 = abcd.get_pci_20()\n",
    "    ifa = abcd.get_ifa()\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, predicted)\n",
    "    except:\n",
    "        auc = 0\n",
    "    print(classification_report(y_test, predicted))\n",
    "    return recall,precision,pf,f1,g_score,auc,pci_20,ifa,importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_df = pd.read_csv('projects.csv')\n",
    "projects = proj_df.repo_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(projects,all_projects):\n",
    "    precision_list = {}\n",
    "    recall_list = {}\n",
    "    pf_list = {}\n",
    "    f1_list = {}\n",
    "    g_list = {}\n",
    "    auc_list = {}\n",
    "    pci_20_list = {}\n",
    "    ifa_list = {}\n",
    "    featue_importance = {}\n",
    "    for project in projects[0:10]:\n",
    "        try:\n",
    "            if project == '.DS_Store':\n",
    "                continue\n",
    "            print(\"+++++++++++++++++   \"  + project + \"  +++++++++++++++++\")\n",
    "            recall,precision,pf,f1,g_score,auc,pci_20,ifa,importance = run_self(project,all_projects)\n",
    "            recall_list[project] = recall\n",
    "            precision_list[project] = precision\n",
    "            pf_list[project] = pf\n",
    "            f1_list[project] = f1\n",
    "            g_list[project] = g_score\n",
    "            auc_list[project] = auc\n",
    "            pci_20_list[project] = pci_20\n",
    "            ifa_list[project] = ifa\n",
    "            featue_importance[project] = importance\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    final_result = {}\n",
    "    final_result['precision'] = precision_list\n",
    "    final_result['recall'] = recall_list\n",
    "    final_result['pf'] = pf_list\n",
    "    final_result['f1'] = f1_list\n",
    "    final_result['g'] = g_list\n",
    "    final_result['auc'] = auc_list\n",
    "    final_result['pci_20'] = pci_20_list\n",
    "    final_result['ifa'] = ifa_list\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects = projects[0:10]\n",
    "threads = []\n",
    "results = {}\n",
    "results['precision'] = {}\n",
    "results['recall'] = {}\n",
    "results['pf'] = {}\n",
    "results['f1'] = {}\n",
    "results['g'] = {}\n",
    "results['auc'] = {}\n",
    "results['pci_20'] = {}\n",
    "results['ifa'] = {}\n",
    "cores = cpu_count()\n",
    "split_projects = np.array_split(projects, cores)\n",
    "for i in range(cores):\n",
    "    print(\"starting thread \",i)\n",
    "    t = ThreadWithReturnValue(target = run, args = [split_projects[i],projects])\n",
    "    threads.append(t)\n",
    "for th in threads:\n",
    "    th.start()\n",
    "for th in threads:\n",
    "    response = th.join()\n",
    "    print(response)\n",
    "    results['precision'].update(response['precision'])\n",
    "    results['recall'].update(response['recall'])\n",
    "    results['pf'].update(response['pf'])\n",
    "    results['f1'].update(response['f1'])\n",
    "    results['g'].update(response['g'])\n",
    "    results['auc'].update(response['auc'])\n",
    "    results['pci_20'].update(response['pci_20'])\n",
    "    results['ifa'].update(response['ifa'])\n",
    "with open('results/Performance/process+product_cross_project.pkl', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('results/Performance/process+product_cross_project.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': {'org.alloytools.alloy': 0.12,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.12,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.0,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.0},\n",
       " 'recall': {'org.alloytools.alloy': 0.84,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.8,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.0,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.0},\n",
       " 'pf': {'org.alloytools.alloy': 0.735,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.45999999999999996,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.16,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.02},\n",
       " 'f1': {'org.alloytools.alloy': 0.33499999999999996,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.33999999999999997,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.0,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.0},\n",
       " 'g': {'org.alloytools.alloy': 0.58,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.63,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.2,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.06},\n",
       " 'auc': {'org.alloytools.alloy': 0.59375,\n",
       "  'qpython': 0.5,\n",
       "  'friendlychat-android': 0.6264038969503619,\n",
       "  'paho.mqtt.android': 0.5,\n",
       "  'paho.mqtt.java': 0.5,\n",
       "  'android-docs-samples': 0.5,\n",
       "  'Toasty': 0.5,\n",
       "  'android-mvvm-architecture': 0.5,\n",
       "  'recipes-rss': 0.5,\n",
       "  'HoloGraphLibrary': 0.5213903743315508},\n",
       " 'pci_20': {'org.alloytools.alloy': 0.665,\n",
       "  'qpython': 0.0,\n",
       "  'friendlychat-android': 0.62,\n",
       "  'paho.mqtt.android': 0.0,\n",
       "  'paho.mqtt.java': 0.0,\n",
       "  'android-docs-samples': 0.0,\n",
       "  'Toasty': 0.625,\n",
       "  'android-mvvm-architecture': 0.0,\n",
       "  'recipes-rss': 0.0,\n",
       "  'HoloGraphLibrary': 0.635},\n",
       " 'ifa': {'org.alloytools.alloy': 3.0,\n",
       "  'qpython': 41.0,\n",
       "  'friendlychat-android': 1.5,\n",
       "  'paho.mqtt.android': 18.0,\n",
       "  'paho.mqtt.java': 41.0,\n",
       "  'android-docs-samples': 41.0,\n",
       "  'Toasty': 25.0,\n",
       "  'android-mvvm-architecture': 41.0,\n",
       "  'recipes-rss': 21.0,\n",
       "  'HoloGraphLibrary': 13.0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

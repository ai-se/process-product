{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,roc_auc_score,recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from src import SMOTE\n",
    "from src import CFS\n",
    "from src import metrices\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project,commits,file_commits):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "    cols_list = understand_df.columns.values.tolist()\n",
    "    for item in ['Kind', 'Name','commit_hash', 'Bugs']:\n",
    "        if item in cols_list:\n",
    "            cols_list.remove(item)\n",
    "            cols_list.insert(0,item)\n",
    "    understand_df = understand_df[cols_list]\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    cols = understand_df.columns.tolist()\n",
    "    \n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['parent_hashes','author_name','author_name',\n",
    "                                                   'author_email','fileschanged','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix', 'contains_bug','fixes',],axis=1)\n",
    "    \n",
    "#     commit_guru_df = commit_guru_df[commit_guru_df['commit_hash'].isin(commits)]\n",
    "    understand_df['file'] = [0]*understand_df.shape[0]\n",
    "    for i in range(understand_df.shape[0]):\n",
    "        understand_df.loc[i,'file'] = understand_df.loc[i,'Name'].split('.')[-1]\n",
    "    sub_df = pd.DataFrame()\n",
    "    for commit in file_commits:\n",
    "        _df = understand_df[understand_df['commit_hash'] == commit]\n",
    "        _df = _df[_df['file'].isin(file_commits[commit]['files'])]\n",
    "        sub_df = pd.concat([sub_df,_df],axis = 0)\n",
    "#     print(sub_df)\n",
    "    understand_df = sub_df\n",
    "#     print(understand_df.shape)\n",
    "#     understand_df = understand_df.drop_duplicates(cols[4:len(cols)])\n",
    "#     print(understand_df.shape)\n",
    "    df = understand_df.merge(commit_guru_df,on='commit_hash')\n",
    "#     print(df.shape)\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "    for item in ['Kind', 'Name','commit_hash','file']:\n",
    "        if item in cols:\n",
    "            df = df.drop(labels = [item],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    y = df.Bugs\n",
    "    X = df.drop('Bugs',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "    return X,y\n",
    "\n",
    "def load_understand_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "    cols_list = understand_df.columns.values.tolist()\n",
    "#     print(cols_list)\n",
    "    for item in ['Kind', 'Name','commit_hash', 'Bugs']:\n",
    "        if item in cols_list:\n",
    "            cols_list.remove(item)\n",
    "            cols_list.insert(0,item)\n",
    "    understand_df = understand_df[cols_list]\n",
    "    cols = understand_df.columns.tolist()\n",
    "    understand_df = understand_df.drop_duplicates(cols[4:len(cols)])\n",
    "    df = understand_df\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "    for item in ['Kind', 'Name']:\n",
    "        if item in cols:\n",
    "            df = df.drop(labels = [item],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_commit_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    \n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['author_name','author_name',\n",
    "                                                   'author_email','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix','fixes',],axis=1)\n",
    "\n",
    "    df = commit_guru_df\n",
    "    df.rename(columns={\"contains_bug\": \"Bugs\"},inplace=True)\n",
    "    y = df.Bugs\n",
    "    X = df.drop('Bugs',axis = 1)\n",
    "    y.fillna(False,inplace=True)\n",
    "    df['Bugs'] = y\n",
    "    df.dropna(inplace=True)\n",
    "    cols = df.columns.tolist()\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def normalize(X):\n",
    "    commit_hash = X.commit_hash\n",
    "    X = X.drop('commit_hash',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "    X['commit_hash'] = commit_hash\n",
    "    return X\n",
    "\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "    y = df.Bugs.values\n",
    "    X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "    X = X.values\n",
    "    selected_cols = CFS.cfs(X,y)\n",
    "    cols = df.columns[[selected_cols]].tolist()\n",
    "    cols.append('Bugs')\n",
    "    return df[cols],cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit_subset_s2(project):\n",
    "    commit_df = load_commit_data(project)\n",
    "    commits = []\n",
    "    file_commits = {}\n",
    "    updated_commits = []\n",
    "    cols = commit_df.columns.values.tolist()\n",
    "    cols.append('file')\n",
    "    commit_df = commit_df[commit_df['Bugs'] == True]\n",
    "    commit_df.reset_index(drop=True,inplace=True)\n",
    "    for i in range(commit_df.shape[0]):\n",
    "        files = commit_df.loc[i,'fileschanged'].split(',')\n",
    "        cleaned_files = [file.split('/')[-1].split('.')[0] for file in files]\n",
    "        parent_hashes = commit_df.loc[i,'parent_hashes']\n",
    "        file_commits[commit_df.loc[i,'commit_hash']] = {'files':cleaned_files,'parent':parent_hashes}\n",
    "        for file in files:\n",
    "            if file.split('.')[-1] == 'java':\n",
    "                commit_info = commit_df.loc[i].values.tolist()\n",
    "                commit_info.append(file)\n",
    "                updated_commits.append(commit_info)\n",
    "    updated_commits_df = pd.DataFrame(updated_commits,columns = cols)\n",
    "    updated_commits_df.drop('fileschanged',axis = 1,inplace = True)\n",
    "    unique_files = updated_commits_df.file.unique()\n",
    "    commits.append(commit_df.commit_hash.values.tolist()) \n",
    "    commits = [val for sublist in commits for val in sublist]\n",
    "    return commits,file_commits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_df = pd.read_csv('projects.csv')\n",
    "projects = proj_df.repo_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(project):\n",
    "    commits,file_commits = get_commit_subset_s2(project)\n",
    "    X,y = load_data(project,commits,file_commits)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "    df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "    df_smote = apply_smote(df_smote)\n",
    "    y_train = df_smote.Bugs\n",
    "    X_train = df_smote.drop('Bugs',axis = 1)\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    abcd = metrices.measures(y_test,predicted)\n",
    "    pf = abcd.get_pf()\n",
    "    recall = abcd.calculate_recall()\n",
    "    precision = abcd.calculate_precision()\n",
    "    f1 = abcd.calculate_f1_score()\n",
    "    g_score = abcd.get_g_score()\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, predicted)\n",
    "    except:\n",
    "        auc = 0\n",
    "    print(classification_report(y_test, predicted))\n",
    "    return recall,precision,pf,f1,g_score,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.98      1.00      0.99        47\n",
      "\n",
      "    accuracy                           0.98        48\n",
      "   macro avg       0.49      0.50      0.49        48\n",
      "weighted avg       0.96      0.98      0.97        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision_list = {}\n",
    "recall_list = {}\n",
    "pf_list = {}\n",
    "f1_list = {}\n",
    "g_list = {}\n",
    "auc_list = {}\n",
    "count = 0\n",
    "for project in projects:\n",
    "    if project != 'JustAuth':\n",
    "        continue\n",
    "    try:\n",
    "        recall,precision,pf,f1,g_score,auc = run(project)\n",
    "        recall_list[project] = recall\n",
    "        precision_list[project] = precision\n",
    "        pf_list[project] = pf\n",
    "        f1_list[project] = f1\n",
    "        g_list[project] = g_score\n",
    "        auc_list[project] = auc\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "final_result = {}\n",
    "final_result['precision'] = precision_list\n",
    "final_result['recall'] = recall_list\n",
    "final_result['pf'] = pf_list\n",
    "final_result['f1'] = f1_list\n",
    "final_result['g'] = g_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

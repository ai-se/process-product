{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.linalg import cholesky\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matlab.engine as engi\n",
    "import matlab as mat\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,roc_auc_score,recall_score,precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from pyearth import Earth\n",
    "\n",
    "from src import SMOTE\n",
    "from src import CFS\n",
    "from src import metrices\n",
    "from src.gcforest.gcforest import GCForest\n",
    "from src.gcforest.utils.config_utils import load_json\n",
    "\n",
    "import platform\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_understand_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    understand_df = pd.read_csv(understand_path)\n",
    "    understand_df = understand_df.dropna(axis = 1,how='all')\n",
    "    cols_list = understand_df.columns.values.tolist()\n",
    "#     print(cols_list)\n",
    "    for item in ['Kind', 'Name','commit_hash', 'Bugs']:\n",
    "        if item in cols_list:\n",
    "            cols_list.remove(item)\n",
    "            cols_list.insert(0,item)\n",
    "    understand_df = understand_df[cols_list]\n",
    "    cols = understand_df.columns.tolist()\n",
    "    understand_df = understand_df.drop_duplicates(cols[4:len(cols)])\n",
    "    df = understand_df\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    df = df[cols]\n",
    "    for item in ['Kind', 'Name']:\n",
    "        if item in cols:\n",
    "            df = df.drop(labels = [item],axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def load_commit_data(project):\n",
    "    understand_path = 'data/understand_files_all/' + project + '_understand.csv'\n",
    "    commit_guru_path = 'data/commit_guru/' + project + '.csv'\n",
    "    commit_guru_df = pd.read_csv(commit_guru_path)\n",
    "    \n",
    "    commit_guru_df = commit_guru_df.drop(labels = ['parent_hashes','author_name','author_name',\n",
    "                                                   'author_email','fileschanged','author_date',\n",
    "                                                   'author_date_unix_timestamp', 'commit_message',\n",
    "                                                  'classification', 'fix','fixes',],axis=1)\n",
    "\n",
    "    df = commit_guru_df\n",
    "    df.rename(columns={\"contains_bug\": \"Bugs\"},inplace=True)\n",
    "    y = df.Bugs\n",
    "    X = df.drop('Bugs',axis = 1)\n",
    "    y.fillna(False,inplace=True)\n",
    "    df['Bugs'] = y\n",
    "    df.dropna(inplace=True)\n",
    "    cols = df.columns.tolist()\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "#     df,cols = apply_cfs(df)\n",
    "#     y = df.Bugs\n",
    "#     X = df.drop('Bugs',axis = 1)\n",
    "    return df\n",
    "\n",
    "def normalize(X):\n",
    "    commit_hash = X.commit_hash\n",
    "    X = X.drop('commit_hash',axis = 1)\n",
    "    cols = X.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(X,columns = cols)\n",
    "    X['commit_hash'] = commit_hash\n",
    "    return X\n",
    "\n",
    "def apply_smote(df):\n",
    "    cols = df.columns\n",
    "    smt = SMOTE.smote(df)\n",
    "    df = smt.run()\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "def apply_cfs(df):\n",
    "        y = df.Bugs.values\n",
    "        X = df.drop(labels = ['Bugs'],axis = 1)\n",
    "        X = X.values\n",
    "        selected_cols = CFS.cfs(X,y)\n",
    "        cols = df.columns[[selected_cols]].tolist()\n",
    "        cols.append('Bugs')\n",
    "        return df[cols],cols\n",
    "\n",
    "def get_toy_config():\n",
    "    config = {}\n",
    "    ca_config = {}\n",
    "    ca_config[\"random_state\"] = 0\n",
    "    ca_config[\"max_layers\"] = 100\n",
    "    ca_config[\"early_stopping_rounds\"] = 3\n",
    "    ca_config[\"n_classes\"] = 2\n",
    "    ca_config[\"estimators\"] = []\n",
    "#     ca_config[\"estimators\"].append(\n",
    "#             {\"n_folds\": 5, \"type\": \"XGBClassifier\", \"n_estimators\": 10, \"max_depth\": 5,\n",
    "#              \"objective\": \"multi:softprob\", \"silent\": True, \"nthread\": -1, \"learning_rate\": 0.1} )\n",
    "    ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"RandomForestClassifier\", \"n_estimators\": 100, \"max_depth\": None, \"n_jobs\": -1})\n",
    "#     ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"ExtraTreesClassifier\", \"n_estimators\": 10, \"max_depth\": None, \"n_jobs\": -1})\n",
    "#     ca_config[\"estimators\"].append({\"n_folds\": 5, \"type\": \"LogisticRegression\"})\n",
    "    config[\"cascade\"] = ca_config\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,df):\n",
    "    lo = df.min()\n",
    "    hi = df.max()\n",
    "    return (x - lo) / (hi - lo +0.00000001)\n",
    "\n",
    "def dominate(_df,t,row_project_name,goals):\n",
    "    wins = 0\n",
    "    for i in range(_df.shape[0]):\n",
    "        project_name = _df.index[i]\n",
    "        row = _df.iloc[i].tolist()\n",
    "        if project_name != row_project_name:\n",
    "            if dominationCompare(row, t,goals,_df):\n",
    "                wins += 1\n",
    "    return wins\n",
    "\n",
    "def dominationCompare(other_row, t,goals,df):\n",
    "    n = len(goals)\n",
    "    weight = {'recall':1,'precision':1,'pf':-2.5}\n",
    "    sum1, sum2 = 0,0\n",
    "    for i in range(len(goals)):\n",
    "        _df = df[goals[i]]\n",
    "        w = weight[goals[i]]\n",
    "        x = t[i]\n",
    "        y = other_row[i]\n",
    "        x = norm(x,_df)\n",
    "        y = norm(y,_df)\n",
    "        sum1 = sum1 - math.e**(w * (x-y)/n)\n",
    "        sum2 = sum2 - math.e**(w * (y-x)/n)\n",
    "    return sum1/n < sum2/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_self(project):\n",
    "    commit_X,commit_y = load_commit_data(project)\n",
    "    understand_X,understand_y = load_understand_data(project)\n",
    "    print(commit_X)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "#     df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "#     df_smote = apply_smote(df_smote)\n",
    "#     y_train = df_smote.Bugs\n",
    "#     X_train = df_smote.drop('Bugs',axis = 1)\n",
    "# #     clf = LogisticRegression(penalty='l1',solver='liblinear')\n",
    "# #     clf = Earth()\n",
    "#     clf = RandomForestClassifier()\n",
    "#     clf.fit(X_train,y_train)\n",
    "# #     print(clf.coef_)\n",
    "#     predicted = clf.predict(X_test)\n",
    "# #     print(predicted)\n",
    "#     abcd = metrices.measures(y_test,predicted)\n",
    "#     pf = abcd.get_pf()\n",
    "#     recall = abcd.calculate_recall()\n",
    "#     precision = abcd.calculate_precision()\n",
    "#     f1 = abcd.calculate_f1_score()\n",
    "#     g_score = abcd.get_g_score()\n",
    "#     try:\n",
    "#         auc = roc_auc_score(y_test, predicted)\n",
    "#     except:\n",
    "#         auc = 0\n",
    "#     print(classification_report(y_test, predicted))\n",
    "#     return recall,precision,pf,f1,g_score,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_df = pd.read_csv('projects.csv')\n",
    "projects = proj_df.repo_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2020-04-02 12:29:31,555][cascade_classifier.fit_transform] X_groups_train.shape=[(1728, 13)],y_train.shape=(1728,),X_groups_test.shape=no_test,y_test.shape=no_test\n",
      "[ 2020-04-02 12:29:31,557][cascade_classifier.fit_transform] group_dims=[13]\n",
      "[ 2020-04-02 12:29:31,558][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2020-04-02 12:29:31,559][cascade_classifier.fit_transform] group_ends=[13]\n",
      "[ 2020-04-02 12:29:31,559][cascade_classifier.fit_transform] X_train.shape=(1728, 13),X_test.shape=(0, 13)\n",
      "[ 2020-04-02 12:29:31,560][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(1728, 13), X_cur_test.shape=(0, 13)\n",
      "[ 2020-04-02 12:29:31,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_0.predict)=90.75%\n",
      "[ 2020-04-02 12:29:32,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_1.predict)=93.93%\n",
      "[ 2020-04-02 12:29:32,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_2.predict)=89.88%\n",
      "[ 2020-04-02 12:29:32,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_3.predict)=89.57%\n",
      "[ 2020-04-02 12:29:32,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_4.predict)=91.01%\n",
      "[ 2020-04-02 12:29:32,806][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 5_folds.train_cv.predict)=91.03%\n",
      "[ 2020-04-02 12:29:32,808][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.03%\n",
      "[ 2020-04-02 12:29:32,810][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(1728, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2020-04-02 12:29:33,059][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_0.predict)=91.04%\n",
      "[ 2020-04-02 12:29:33,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_1.predict)=91.62%\n",
      "[ 2020-04-02 12:29:33,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_2.predict)=88.73%\n",
      "[ 2020-04-02 12:29:33,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_3.predict)=92.46%\n",
      "[ 2020-04-02 12:29:34,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_4.predict)=92.75%\n",
      "[ 2020-04-02 12:29:34,071][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 5_folds.train_cv.predict)=91.32%\n",
      "[ 2020-04-02 12:29:34,073][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=91.32%\n",
      "[ 2020-04-02 12:29:34,075][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(1728, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2020-04-02 12:29:34,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_0.predict)=91.91%\n",
      "[ 2020-04-02 12:29:34,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_1.predict)=89.02%\n",
      "[ 2020-04-02 12:29:34,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_2.predict)=90.75%\n",
      "[ 2020-04-02 12:29:35,079][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_3.predict)=92.75%\n",
      "[ 2020-04-02 12:29:35,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_4.predict)=93.33%\n",
      "[ 2020-04-02 12:29:35,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 5_folds.train_cv.predict)=91.55%\n",
      "[ 2020-04-02 12:29:35,334][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=91.55%\n",
      "[ 2020-04-02 12:29:35,335][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(1728, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2020-04-02 12:29:35,585][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_0.predict)=87.86%\n",
      "[ 2020-04-02 12:29:35,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_1.predict)=92.49%\n",
      "[ 2020-04-02 12:29:36,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_2.predict)=91.91%\n",
      "[ 2020-04-02 12:29:36,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_3.predict)=90.43%\n",
      "[ 2020-04-02 12:29:36,587][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_4.predict)=93.33%\n",
      "[ 2020-04-02 12:29:36,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 5_folds.train_cv.predict)=91.20%\n",
      "[ 2020-04-02 12:29:36,591][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=91.20%\n",
      "[ 2020-04-02 12:29:36,593][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(1728, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2020-04-02 12:29:36,839][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_0.predict)=91.91%\n",
      "[ 2020-04-02 12:29:37,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_1.predict)=89.02%\n",
      "[ 2020-04-02 12:29:37,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_2.predict)=90.75%\n",
      "[ 2020-04-02 12:29:37,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_3.predict)=90.14%\n",
      "[ 2020-04-02 12:29:37,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_4.predict)=91.88%\n",
      "[ 2020-04-02 12:29:37,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 5_folds.train_cv.predict)=90.74%\n",
      "[ 2020-04-02 12:29:37,839][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=90.74%\n",
      "[ 2020-04-02 12:29:37,841][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(1728, 15), X_cur_test.shape=(0, 15)\n",
      "[ 2020-04-02 12:29:38,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_0.predict)=91.33%\n",
      "[ 2020-04-02 12:29:38,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_1.predict)=91.91%\n",
      "[ 2020-04-02 12:29:38,584][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_2.predict)=90.75%\n",
      "[ 2020-04-02 12:29:38,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_3.predict)=89.57%\n",
      "[ 2020-04-02 12:29:39,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_4.predict)=89.86%\n",
      "[ 2020-04-02 12:29:39,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 5_folds.train_cv.predict)=90.68%\n",
      "[ 2020-04-02 12:29:39,089][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=90.68%\n",
      "[ 2020-04-02 12:29:39,091][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=3, accuracy_train=91.55%, accuracy_test=0.00%\n",
      "[ 2020-04-02 12:29:39,096][cascade_classifier.transform] X_groups_test.shape=[(705, 13)]\n",
      "[ 2020-04-02 12:29:39,097][cascade_classifier.transform] group_dims=[13]\n",
      "[ 2020-04-02 12:29:39,098][cascade_classifier.transform] X_test.shape=(705, 13)\n",
      "[ 2020-04-02 12:29:39,099][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(705, 13)\n",
      "[ 2020-04-02 12:29:39,631][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(705, 15)\n",
      "[ 2020-04-02 12:29:40,167][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(705, 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.94      0.92       563\n",
      "        True       0.71      0.56      0.62       142\n",
      "\n",
      "    accuracy                           0.87       705\n",
      "   macro avg       0.80      0.75      0.77       705\n",
      "weighted avg       0.86      0.87      0.86       705\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.91      0.92      0.91       563\n",
      "        True       0.66      0.63      0.64       142\n",
      "\n",
      "    accuracy                           0.86       705\n",
      "   macro avg       0.78      0.77      0.78       705\n",
      "weighted avg       0.86      0.86      0.86       705\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       939\n",
      "           1       0.67      0.59      0.63       829\n",
      "\n",
      "    accuracy                           0.67      1768\n",
      "   macro avg       0.67      0.67      0.67      1768\n",
      "weighted avg       0.67      0.67      0.67      1768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74       939\n",
      "           1       0.69      0.89      0.78       829\n",
      "\n",
      "    accuracy                           0.76      1768\n",
      "   macro avg       0.78      0.77      0.76      1768\n",
      "weighted avg       0.78      0.76      0.76      1768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.70       624\n",
      "           1       0.72      0.91      0.81       735\n",
      "\n",
      "    accuracy                           0.76      1359\n",
      "   macro avg       0.79      0.75      0.75      1359\n",
      "weighted avg       0.78      0.76      0.76      1359\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       939\n",
      "           1       0.72      0.81      0.76       829\n",
      "\n",
      "    accuracy                           0.77      1768\n",
      "   macro avg       0.77      0.77      0.77      1768\n",
      "weighted avg       0.77      0.77      0.77      1768\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77       939\n",
      "           1       0.72      0.86      0.78       829\n",
      "\n",
      "    accuracy                           0.78      1768\n",
      "   macro avg       0.78      0.78      0.78      1768\n",
      "weighted avg       0.79      0.78      0.78      1768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for project in projects:\n",
    "    if project != 'parquet-mr':\n",
    "        continue\n",
    "    \n",
    "    # Process Data\n",
    "    commit_df = load_commit_data(project)\n",
    "    commit_y = commit_df.Bugs\n",
    "    commit_X = commit_df.drop('Bugs',axis = 1)\n",
    "    commit_X = normalize(commit_X)\n",
    "    commit_X_train, commit_X_test, commit_y_train, commit_y_test = train_test_split(commit_X, \n",
    "                                                                                    commit_y, \n",
    "                                                                                    test_size=0.40, \n",
    "                                                                                    random_state=18)\n",
    "    \n",
    "    # Product Data\n",
    "    understand_df = load_understand_data(project)\n",
    "    understand_y = understand_df.Bugs\n",
    "    understand_X = understand_df.drop('Bugs',axis = 1)\n",
    "    understand_X = normalize(understand_X)\n",
    "    understand_df['Bugs'] = understand_y\n",
    "    understand_df_train = understand_df[understand_df['commit_hash'].isin(commit_X_train.commit_hash)]\n",
    "    understand_df_test = understand_df[understand_df['commit_hash'].isin(commit_X_test.commit_hash)]\n",
    "    understand_y_train = understand_df_train.Bugs\n",
    "    understand_X_train = understand_df_train.drop('Bugs',axis = 1)\n",
    "    understand_y_test = understand_df_test.Bugs\n",
    "    understand_X_test = understand_df_test.drop('Bugs',axis = 1)\n",
    "    \n",
    "    \n",
    "    # Combined Data\n",
    "    combined_df = understand_df.merge(commit_X,on='commit_hash')\n",
    "    cols = combined_df.columns.tolist()\n",
    "    cols.remove('Bugs')\n",
    "    cols.append('Bugs')\n",
    "    combined_df = combined_df[cols]\n",
    "    combined_df_train = combined_df[combined_df['commit_hash'].isin(commit_X_train.commit_hash)]\n",
    "    combined_df_test = combined_df[combined_df['commit_hash'].isin(commit_X_test.commit_hash)]\n",
    "    combined_y_train = combined_df_train.Bugs\n",
    "    combined_X_train = combined_df_train.drop('Bugs',axis = 1)\n",
    "    combined_y_test = combined_df_test.Bugs\n",
    "    combined_X_test = combined_df_test.drop('Bugs',axis = 1)\n",
    "    \n",
    "    \n",
    "    # Feature Adding to combined data\n",
    "    commit_df_new = pd.concat([commit_X_train,commit_y_train],axis = 1)\n",
    "    commit_df_new.rename(columns={\"Bugs\": \"contains_bug\"},inplace=True)\n",
    "    featured_combined_df = understand_df_train.merge(commit_df_new,on='commit_hash')\n",
    "    cols = featured_combined_df.columns.tolist()\n",
    "    cols.remove('Bugs')\n",
    "    cols.append('Bugs')\n",
    "    featured_combined_df = featured_combined_df[cols]\n",
    "    featured_combined_y_train = featured_combined_df.Bugs\n",
    "    featured_combined_X_train = featured_combined_df.drop('Bugs',axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Test Data with commit_hash\n",
    "    commit_X_test_w = copy.deepcopy(commit_X_test)\n",
    "    \n",
    "    # Removing commit hash\n",
    "    commit_X_train = commit_X_train.drop('commit_hash',axis = 1)\n",
    "    commit_X_test = commit_X_test.drop('commit_hash',axis = 1)\n",
    "    understand_X_train = understand_X_train.drop('commit_hash',axis = 1)\n",
    "    understand_X_test = understand_X_test.drop('commit_hash',axis = 1)\n",
    "    combined_X_train = combined_X_train.drop('commit_hash',axis = 1)\n",
    "    combined_X_test = combined_X_test.drop('commit_hash',axis = 1)\n",
    "    featured_combined_X_train = featured_combined_X_train.drop('commit_hash',axis = 1)\n",
    "    \n",
    "    \n",
    "    # Smote Process Data\n",
    "    commit_df_smote = pd.concat([commit_X_train,commit_y_train],axis = 1)\n",
    "    commit_df_smote = apply_smote(commit_df_smote)\n",
    "    commit_y_train = commit_df_smote.Bugs\n",
    "    commit_X_train = commit_df_smote.drop('Bugs',axis = 1)\n",
    "    \n",
    "    # Smote Product Data\n",
    "    understand_df_smote = pd.concat([understand_X_train,understand_y_train],axis = 1)\n",
    "    understand_df_smote = apply_smote(understand_df_smote)\n",
    "    understand_y_train = understand_df_smote.Bugs\n",
    "    understand_X_train = understand_df_smote.drop('Bugs',axis = 1)\n",
    "    \n",
    "    # Smote Combined Data\n",
    "    combined_df_smote = pd.concat([combined_X_train,combined_y_train],axis = 1)\n",
    "    combined_df_smote = apply_smote(combined_df_smote)\n",
    "    combined_y_train = combined_df_smote.Bugs\n",
    "    combined_X_train = combined_df_smote.drop('Bugs',axis = 1)\n",
    "    \n",
    "    # Smote Feature Combined Data\n",
    "    feature_combined_df_smote = pd.concat([featured_combined_X_train,featured_combined_y_train],axis = 1)\n",
    "    feature_combined_df_smote = apply_smote(feature_combined_df_smote)\n",
    "    featured_combined_y_train = feature_combined_df_smote.Bugs\n",
    "    featured_combined_X_train = feature_combined_df_smote.drop('Bugs',axis = 1)\n",
    "    \n",
    "#     # Normalize Train Data\n",
    "#     commit_X_train = normalize(commit_X_train)\n",
    "#     understand_X_train = normalize(understand_X_train)\n",
    "#     combined_X_train = normalize(combined_X_train)\n",
    "#     featured_combined_X_train = normalize(featured_combined_X_train)\n",
    "    \n",
    "#     # Normalize Test Data \n",
    "#     commit_X_test = normalize(commit_X_test)\n",
    "#     understand_X_test = normalize(understand_X_test)\n",
    "#     combined_X_test = normalize(combined_X_test)\n",
    "\n",
    "    config = get_toy_config()\n",
    "    gc = GCForest(config)\n",
    "    X_train_enc = gc.fit_transform(commit_X_train.values, commit_y_train.values)\n",
    "    y_pred = gc.predict(commit_X_test.values)\n",
    "    print(classification_report(commit_y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Process Classifier\n",
    "    clf_process = RandomForestClassifier()\n",
    "    clf_process.fit(commit_X_train,commit_y_train)\n",
    "    \n",
    "    # Product Classifier\n",
    "    clf_product = RandomForestClassifier()\n",
    "    clf_product.fit(understand_X_train,understand_y_train)\n",
    "    \n",
    "    # Combined Classifier\n",
    "    clf_combined = RandomForestClassifier()\n",
    "    clf_combined.fit(combined_X_train,combined_y_train)\n",
    "    \n",
    "    # Added feature Classifier\n",
    "    clf_feature_combined = RandomForestClassifier()\n",
    "    clf_feature_combined.fit(featured_combined_X_train,featured_combined_y_train)\n",
    "    \n",
    "    # Process Prediction\n",
    "    process_predicted = clf_process.predict(commit_X_test)\n",
    "    print(classification_report(commit_y_test, process_predicted))\n",
    "    \n",
    "    # Product Prediction\n",
    "    product_predicted = clf_product.predict(understand_X_test)\n",
    "    print(classification_report(understand_y_test, product_predicted))\n",
    "    \n",
    "    # Combined Prediction\n",
    "    combined_predicted = clf_combined.predict(combined_X_test)\n",
    "    print(classification_report(combined_y_test, combined_predicted))\n",
    "    \n",
    "    # 2 stage classifier\n",
    "    commit_test_df_w = copy.deepcopy(commit_X_test_w)\n",
    "    commit_test_df_w['Bugs'] = process_predicted\n",
    "    \n",
    "    # true returned from process prediction\n",
    "    commit_test_df_true = commit_test_df_w[commit_test_df_w['Bugs'] == True]\n",
    "    sub_true_combined_df_test = combined_df_test[combined_df_test['commit_hash'].isin(commit_test_df_true.commit_hash)]\n",
    "    sub_true_combined_y_test = sub_true_combined_df_test.Bugs\n",
    "    sub_true_combined_X_test = sub_true_combined_df_test.drop('Bugs',axis = 1)\n",
    "    sub_true_combined_X_test = sub_true_combined_X_test.drop('commit_hash',axis = 1)\n",
    "    sub_true_combined_predicted = clf_combined.predict(sub_true_combined_X_test)\n",
    "    \n",
    "    # false returned from process prediction\n",
    "    commit_test_df_false = commit_test_df_w[commit_test_df_w['Bugs'] == False]\n",
    "    sub_false_combined_df_test = combined_df_test[combined_df_test['commit_hash'].isin(commit_test_df_false.commit_hash)]\n",
    "    sub_false_combined_y_test = sub_false_combined_df_test.Bugs\n",
    "    sub_false_combined_X_test = sub_false_combined_df_test.drop('Bugs',axis = 1)\n",
    "    sub_false_combined_X_test = sub_false_combined_X_test.drop('commit_hash',axis = 1)\n",
    "    sub_flase_combined_predicted = [0]*sub_false_combined_X_test.shape[0]\n",
    "    \n",
    "    final_staged_y_test = list(sub_true_combined_y_test) + list(sub_false_combined_y_test)\n",
    "    final_staged_combined_predicted = list(sub_true_combined_predicted) + list(sub_flase_combined_predicted)\n",
    "    \n",
    "    print(classification_report(sub_true_combined_y_test, sub_true_combined_predicted))\n",
    "    \n",
    "    print(classification_report(final_staged_y_test, final_staged_combined_predicted))\n",
    "    \n",
    "    # Added feature classifier\n",
    "    commit_X_test_w['contains_bug'] = process_predicted\n",
    "    featured_combined_df_test = understand_df_test.merge(commit_X_test_w,on='commit_hash')\n",
    "    featured_combined_df_test = featured_combined_df_test.drop('commit_hash',axis = 1)\n",
    "    featured_combined_y_test = featured_combined_df_test.Bugs\n",
    "    featured_combined_X_test = featured_combined_df_test.drop('Bugs',axis = 1)\n",
    "#     combined_X_test = normalize(combined_X_test)\n",
    "    featured_combined_predicted = clf_feature_combined.predict(featured_combined_X_test)\n",
    "    print(classification_report(featured_combined_y_test, featured_combined_predicted))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       False       0.91      0.94      0.92       563\n",
    "        True       0.72      0.63      0.67       142\n",
    "\n",
    "    accuracy                           0.88       705\n",
    "   macro avg       0.81      0.78      0.80       705\n",
    "weighted avg       0.87      0.88      0.87       705\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.74      0.71       939\n",
    "           1       0.68      0.61      0.64       829\n",
    "\n",
    "    accuracy                           0.68      1768\n",
    "   macro avg       0.68      0.68      0.68      1768\n",
    "weighted avg       0.68      0.68      0.68      1768\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.86      0.64      0.74       939\n",
    "           1       0.68      0.89      0.77       829\n",
    "\n",
    "    accuracy                           0.76      1768\n",
    "   macro avg       0.77      0.76      0.75      1768\n",
    "weighted avg       0.78      0.76      0.75      1768\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.58      0.69       641\n",
    "           1       0.71      0.91      0.80       740\n",
    "\n",
    "    accuracy                           0.76      1381\n",
    "   macro avg       0.78      0.74      0.74      1381\n",
    "weighted avg       0.78      0.76      0.75      1381\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.71      0.76       939\n",
    "           1       0.71      0.81      0.76       829\n",
    "\n",
    "    accuracy                           0.76      1768\n",
    "   macro avg       0.76      0.76      0.76      1768\n",
    "weighted avg       0.77      0.76      0.76      1768\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.71      0.76       939\n",
    "           1       0.72      0.84      0.77       829\n",
    "\n",
    "    accuracy                           0.77      1768\n",
    "   macro avg       0.77      0.77      0.77      1768\n",
    "weighted avg       0.78      0.77      0.77      1768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = {}\n",
    "recall_list = {}\n",
    "pf_list = {}\n",
    "f1_list = {}\n",
    "g_list = {}\n",
    "auc_list = {}\n",
    "for project in projects:\n",
    "    try:\n",
    "        if project == '.DS_Store':\n",
    "            continue\n",
    "#         if project != 'org.alloytools.alloy':\n",
    "#             continue\n",
    "    #     if project != 'guice':\n",
    "    #         continue\n",
    "        print(\"+++++++++++++++++   \"  + project + \"  +++++++++++++++++\")\n",
    "        recall,precision,pf,f1,g_score,auc = run_self(project)\n",
    "        recall_list[project] = recall\n",
    "        precision_list[project] = precision\n",
    "        pf_list[project] = pf\n",
    "        f1_list[project] = f1\n",
    "        g_list[project] = g_score\n",
    "        auc_list[project] = auc\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "final_result = {}\n",
    "final_result['precision'] = precision_list\n",
    "final_result['recall'] = recall_list\n",
    "final_result['pf'] = pf_list\n",
    "final_result['f1'] = f1_list\n",
    "final_result['g'] = g_list\n",
    "final_result['auc'] = auc_list\n",
    "with open('data/self_1000.pkl', 'wb') as handle:\n",
    "    pickle.dump(final_result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_precision = list(precision_list.values())\n",
    "_recall = list(recall_list.values())\n",
    "_pf = list(pf_list.values())\n",
    "_f1 = list(f1_list.values())\n",
    "_g = list(g_list.values())\n",
    "_auc = list(auc_list.values())\n",
    "print(np.median(_precision),np.median(_recall),np.median(_pf),np.median(_f1),np.median(_g),np.median(_auc))\n",
    "fig = plt.figure(num=None, figsize = (20,4), facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(161)\n",
    "ax.boxplot(_precision)\n",
    "ax.set_title('Precision',size = 15)\n",
    "ax = fig.add_subplot(162)\n",
    "ax.boxplot(_recall)\n",
    "ax.set_title('Recall',size = 15)\n",
    "ax = fig.add_subplot(163)\n",
    "ax.boxplot(_pf)\n",
    "ax.set_title('pf',size = 15)\n",
    "ax = fig.add_subplot(164)\n",
    "ax.boxplot(_f1)\n",
    "ax.set_title('f1',size = 15)\n",
    "ax = fig.add_subplot(165)\n",
    "ax.boxplot(_g)\n",
    "ax.set_title('g',size = 15)\n",
    "ax = fig.add_subplot(166)\n",
    "ax.boxplot(_auc)\n",
    "ax.set_title('auc',size = 15)\n",
    "# fig.savefig('without_process.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_self(project):\n",
    "    X,y = load_data(project)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "    df_smote = pd.concat([X_train,y_train],axis = 1)\n",
    "    df_smote = apply_smote(df_smote)\n",
    "    y_train = df_smote.Bugs\n",
    "    X_train = df_smote.drop('Bugs',axis = 1)\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train,y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = {}\n",
    "recall_list = {}\n",
    "pf_list = {}\n",
    "f1_list = {}\n",
    "g_list = {}\n",
    "auc_list = {}\n",
    "for s_project in projects:\n",
    "    try:\n",
    "        if project == '.DS_Store':\n",
    "            continue\n",
    "    #     if project != 'guice':\n",
    "    #         continue\n",
    "        print(\"+++++++++++++++++   \"  + s_project + \"  +++++++++++++++++\")\n",
    "        clf = run_self(s_project)\n",
    "        if s_project not in precision_list.keys():\n",
    "            precision_list[s_project] = {}\n",
    "            recall_list[s_project] = {}\n",
    "            pf_list[s_project] = {}\n",
    "            f1_list[s_project] = {}\n",
    "            g_list[s_project] = {}\n",
    "            auc_list[s_project] = {}    \n",
    "        for d_project in projects:\n",
    "            try:\n",
    "                X,y = load_data(d_project)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=18)\n",
    "                predicted = clf.predict(X_test)\n",
    "                abcd = metrices.measures(y_test,predicted)\n",
    "                pf = abcd.get_pf()\n",
    "                recall = abcd.calculate_recall()\n",
    "                precision = abcd.calculate_precision()\n",
    "                f1 = abcd.calculate_f1_score()\n",
    "                g_score = abcd.get_g_score()\n",
    "                auc = roc_auc_score(y_test, predicted)\n",
    "                precision_list[s_project][d_project] = precision\n",
    "                recall_list[s_project][d_project] = recall\n",
    "                pf_list[s_project][d_project] = pf\n",
    "                f1_list[s_project][d_project] = f1\n",
    "                g_list[s_project][d_project] = g_score\n",
    "                auc_list[s_project][d_project] = auc\n",
    "            except Exception as e:\n",
    "                print('d_project',e)\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print('s_project',e)\n",
    "        continue\n",
    "final_result = {}\n",
    "final_result['precision'] = precision_list\n",
    "final_result['recall'] = recall_list\n",
    "final_result['pf'] = pf_list\n",
    "final_result['f1'] = f1_list\n",
    "final_result['g'] = g_list\n",
    "final_result['auc'] = auc_list\n",
    "with open('data/conv_bellwether_100.pkl', 'wb') as handle:\n",
    "    pickle.dump(final_result, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_self = pd.read_pickle('data/self_100.pkl')\n",
    "df_bellwether = pd.read_pickle('data/conv_bellwether_100.pkl')\n",
    "metrices = df_self.keys()\n",
    "median = 0\n",
    "median_results = {}\n",
    "for s_project in projects:\n",
    "    try:\n",
    "        if s_project not in median_results.keys():\n",
    "            median_results[s_project] = {}\n",
    "        for metric in metrices:\n",
    "            median_results[s_project][metric] = np.median(list(df_bellwether[metric][s_project].values()))\n",
    "    except Exception as e:\n",
    "        print(s_project)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(median_results,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result/cdom_score_100.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom_score = []\n",
    "goals = ['recall','precision','pf']\n",
    "for row_id in range(df.shape[0]):\n",
    "    project_name = df.index[row_id]\n",
    "    row = df.iloc[row_id].tolist()\n",
    "    wins = dominate(df,row,project_name,goals)\n",
    "    dom_score.append(wins)\n",
    "df['wins'] = dom_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['wins'] == df.wins.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_self = pd.read_pickle('data/self_100.pkl')\n",
    "df_bellwether = pd.read_pickle('data/conv_bellwether_100.pkl')\n",
    "metrices = df_self.keys()\n",
    "median = 0\n",
    "bell_results = {}\n",
    "for s_project in projects:\n",
    "    try:\n",
    "        for metric in metrices:\n",
    "            if metric not in bell_results.keys():\n",
    "                bell_results[metric] = {}\n",
    "            if s_project not in bell_results[metric]:\n",
    "                bell_results[metric][s_project] = {}\n",
    "            _self = df_self[metric][s_project]\n",
    "            _bell = df_bellwether[metric]['disruptor'][s_project]\n",
    "            bell_results[metric][s_project]['self'] = _self\n",
    "            bell_results[metric][s_project]['bell'] = _bell\n",
    "    except Exception as e:\n",
    "        print(s_project)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrices:\n",
    "    count = 0\n",
    "    for key in bell_results[metric].keys():\n",
    "        try:\n",
    "            if  bell_results[metric][key]['self'] <= bell_results[metric][key]['bell']:\n",
    "                count += 1\n",
    "        except:\n",
    "            continue\n",
    "    print(metric, \"wins\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
